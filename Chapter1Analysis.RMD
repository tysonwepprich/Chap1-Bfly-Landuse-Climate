---
title: "Chapter 1 Analysis"
author: "Tyson Wepprich"
date: "February 12, 2016"
output: html_document
---

Plan:
Hierarchical models in lmer for testing the weather x land-use interaction for
each of 40 butterfly species. Does including land-use (climate known to be important)
improve the predictive ability of models?

TODO:
Add in new 2013-2014 data. 
Clean up and rerun regional GAMs to get population indices.
Potential to add in GDD into GAM, in addition to simple latitude.
Population index: Trapezoid vs GAM curve vs collated index.
Response: Growth rate or abundance?
Feature selection for climate and landuse:
- PCA of 7 land-use/land-cover classes. (Impervious?)
- PCA of many potential climate variables. Temp, precip, snow most important.
  Debate over whether just clustered sites, or points from whole state.
  Also, just years of monitoring, or from 1980 to show variation.
  Anomalies or site x year fed into PCA?
Finally, the model!
- Split data into train and test sets (random or by year/site?)
- Lmer mixed-effects models, variable selection for fixed adn random effects.
- 

```{r packages, echo=FALSE}
list.of.packages <- c("devtools", "parallel", "plyr", "dplyr", "tidyr", 
                      "readr", "data.table", "mgcv", "lubridate", "lme4",
                      "MuMIn")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages) > 0) install.packages(new.packages)

library(devtools)
library(parallel)
library(plyr)
library(dplyr)
library(tidyr)
library(readr)
library(data.table)
library(mgcv)
library(lubridate)
library(lme4)
library(MuMIn)

source('chap1functions.R')
source('spatiotempLOO.R')

```

Bring together raw data. 15 new sites in 2013-2014 without geo/region/landuse information.

```{r, echo=FALSE}

setwd("C:/Users/Tyson/Desktop/Box Sync/Ohio/data2012")
data <- fread("data.trim.csv", header = TRUE)
data <- data[, list(SeqID, SiteID.x, SiteDate, Week, Total, CheckListKey, CommonName)]
setnames(data,"SiteID.x","SiteID")
data[, SiteID := formatC(SiteID, width = 3, format = "d", flag = "0")]
data[, SiteDate := ymd(as.character(SiteDate))]


region <- fread("site_region.txt", header = TRUE)
region[, SiteID := formatC(SiteID, width = 3, format = "d", flag = "0")]
data <- merge(data, region, by = "SiteID")
setkey(data, SeqID)
data$CommonName <- plyr::mapvalues(data$CommonName, from = "Spring/Summer Azure", to = "Azures")


surveys <- distinct(data[, c("SeqID", "SiteID", "SiteDate", "Region", "Week"), with = FALSE])

SpeciesNum <- data %>%
  group_by(CommonName) %>%
  summarise(Present = length(Total)) %>%
  arrange(-Present) %>%
  data.frame()

SpeciesList <- SpeciesNum[-grep("Unidentified", SpeciesNum$CommonName, fixed = TRUE), ]
SpeciesList <- SpeciesList[-which(SpeciesList$CommonName == "None seen this day"), ]
SpeciesList$CommonName <- plyr::mapvalues(SpeciesList$CommonName, from = "Spring/Summer Azure", to = "Azures")

# SpeciesList <- filter(SpeciesList, Present > 30)
saveRDS(SpeciesList, file = "SpeciesList.rds")

site_geo <- fread("C:/Users/Tyson/Desktop/Box Sync/Ohio/GIS/OHsites_reconciled.csv", header = TRUE)
site_geo[, SiteID := formatC(as.numeric(Name), width = 3, format = "d", flag = "0")]

setwd("C:/Users/Tyson/REPO/Chap1-Bfly-Landuse-Climate/")

```

Clean up counts with outlier detection to prepare for Regional GAM.
Function counts the number of days separating an observation of a species with 
any other observation of the same species within the region (at same site, too).
This may remove interesting observations, but in reality will only cut observations
from sites that miss lots of weeks, or stray observations of less common species.
Save each species' counts in rds file.

```{r outliers, eval=FALSE}

##############################################
#run outlier detection for all, save counts since this is slow
species <- as.character(SpeciesList$CommonName)
species <- species[5:100]
# species[5] <- "Azures"

for (sp in species){
  
  print(sp)
  spdat <- data[CommonName == sp]
  spdat <- unique(spdat) #not sure why there would be duplicates!
  setkey(spdat, SeqID)
  
  #Add zeros to surveys when species not counted during a survey
  #Results in dataset will all 20383 surveys
  
  test <- merge(surveys, spdat, by = c("SeqID", "SiteID", "SiteDate", "Region", "Week"), all.x = TRUE)
  counts <- test[, `:=` (CheckListKey = NULL,
                         CommonName = NULL)]
  counts$Total <- plyr::mapvalues(counts[,Total], from = NA, to = 0)
  
  #Filter dataset
  #Remove pilot year
  counts <- counts[year(SiteDate) > 1995]
  counts[, GrandTotal := sum(Total), by = "SiteID"]
  counts <- counts[GrandTotal > 0]

  counts[, Ordinal := yday(SiteDate)]
  counts[, Year := year(SiteDate)]
  
  rawcounts <- OutlierDetect(counts)
  
  saveRDS(rawcounts, file = paste("RDSfiles/rawcounts", sp, ".rds", sep = ""))
  
}

#how does outlier removal affect counts?
# curious for multivoltine chapter, testing against whole state rather than 4 regions
# maybe not that big a deal with bootstrap?

# species <- read.csv("../multivoltine/data/MultivoltineSpecies.csv")[,1]
# 
# output <- list()
# for (sp in species){
# 
#   print(sp)
#   spdat <- data[CommonName == sp]
#   spdat <- unique(spdat) #not sure why there would be duplicates!
#   setkey(spdat, SeqID)
#   
#   #Add zeros to surveys when species not counted during a survey
#   #Results in dataset will all 20383 surveys
#   
#   test <- merge(surveys, spdat, by = c("SeqID", "SiteID", "SiteDate", "Region", "Week"), all.x = TRUE)
#   counts <- test[, `:=` (CheckListKey = NULL,
#                          CommonName = NULL)]
#   counts$Total <- plyr::mapvalues(counts[,Total], from = NA, to = 0)
#   
#   #Filter dataset
#   #Remove pilot year
#   counts <- counts[year(SiteDate) > 1995]
#   counts[, GrandTotal := sum(Total), by = "SiteID"]
#   counts <- counts[GrandTotal > 0]
# 
#   counts[, Ordinal := yday(SiteDate)]
#   counts[, Year := year(SiteDate)]
#   counts[, Region := "ALL"]
#   
#   counts[, `:=` (SurvPerYear = length(unique(SeqID)),
#                            YearTotal = sum(Total)), 
#                    by = list(SiteID, Year)]
#   
#   counts <- counts[Total > 0]
#   
#   rawcounts <- OutlierDetect(counts)
#   rawcounts[, CommonName := sp]
#   #Filter dataset of outlying counts
#   output[[sp]] <- rawcounts
# }
# 
# mvcounts <- rbindlist(output)
# mv <- mvcounts %>%
#   filter(YearTotal >=5 & SurvPerYear >=15)
# mv <- mv %>%
#   group_by(CommonName, Year, SiteID) %>%
#   mutate(DaysPresent = length(which(Total > 0))) %>%
#   filter(DaysPresent >= 3)


```

Here's where the regional GAM comes in.
Fills in missing weeks, but also could be used as index (area under fligth curve).
Has limits, when few counts of species at site just use raw counts.

Issues:
- GAM with latitude, lat/lon, or GDD
- Neg binomial worked best last time for GAM family
- Collated index not precisely like UKBMS (no overdispersion or serial correlation)
- Sites coded as numeric??


```{r population indices}


#MASSIVE FOR LOOP TO ANALYZE POPULATIONS OF MANY SPECIES
#Problem with "Spring/Summer Azure" name when writing file in directory
SpeciesList <- readRDS("SpeciesList.rds")

region <- data.table(read.csv("C:/Users/Tyson/Desktop/Box Sync/Ohio/data2012/site_region.txt", header = TRUE))
region$SiteID <- formatC(as.numeric(as.character(region$SiteID)), width = 3, format = "d", flag = "0")


# rerunning to include population zeros
# these species worked last time
allcounts_files <- list.files("RDSfiles", pattern = "allcounts")
species <- unlist(strsplit(allcounts_files, "allcounts", fixed = TRUE))[seq(2,130,2)]
species <- unlist(strsplit(species, "[.]"))[seq(1,129,2)]


# species <- as.character(SpeciesList$CommonName)
# species <- species[20:53]
for (sp in species){
  counts <- readRDS(paste("RDSfiles/rawcounts", sp, ".rds", sep = ""))
  counts <- merge(counts, site_geo, by = "SiteID")
  print(sp)
  
  #Filter dataset of outlying counts
  counts <- counts[DaysOut <= 28]
  counts <- counts[, `:=` (SurvPerYear = length(unique(SeqID)),
                           YearTotal = sum(Total)), 
                   by = list(SiteID, Year)]
#   counts[, Ordinal := yday(SiteDate)]
#   counts[, Year := year(SiteDate)]
  
  #Data restrictions for coming up with regional phenology
  #Site must have >= 3 seen, >= 10 surveys, more than 3 sites in Region for GAM
  datGAM <- counts[YearTotal >= 3]
  datGAM <- datGAM[SurvPerYear >= 10]
  datGAM[, SitesObserved := length(unique(SiteID)), by = list(Year)]
  datGAM <- datGAM[SitesObserved >= 5]
  if(nrow(datGAM) == 0) next

  years <- sort(as.numeric(unique(datGAM$Year)))
  alldatGAM <- data.frame()
  phen_all <- data.frame()
  for (yr in years){
    if(dim(datGAM[Year == yr])[1] == 0) next
    if(dim(datGAM[Year == yr][Total > 1])[1] == 0) next
    #                 print(r)
    print(yr)
    phen <- ScaledPhenologyNB(datGAM, yr)
    phen_all <- rbind(phen_all, phen)
    dat_mod <- merge(datGAM, phen, by = c("Year", "Ordinal", "SiteID"))
    alldatGAM <- rbind(alldatGAM, dat_mod)
  }
    
  
  alldatGAM$Year <- as.factor(alldatGAM$Year)
  alldatGAM$SiteID <- as.factor(alldatGAM$SiteID)
  if (length(unique(alldatGAM$Year)) == 1){
    mod <- glm(Total ~ SiteID + offset(log(Gamma)), family = poisson(link = "log"), data = alldatGAM, control = list(maxit = 100))
    }else{
      mod <- glm(Total ~ SiteID + Year + offset(log(Gamma)), family = poisson(link = "log"), data = alldatGAM, control = list(maxit = 100))
      }
  
  #Most restrictive data requirements to come up with a population index for a site
  #Surveys >= 10, and GAM created for that region x year => fill in gaps with GAM/GLM
  datPop <- counts[YearTotal >= 3]
  datPop <- datPop[SurvPerYear >= 10]
  datPop[, SitesObserved := length(unique(SiteID)), by = list(Year)]
  datPop <- datPop[SitesObserved >= 5]
#   datPop[, SitesPerRegion := length(unique(SiteID)), by = list(Region, Year)]
#   datPop <- datPop[SitesPerRegion >= 3]
  missing <- MissingDays(datPop)
#   to_predict <- merge(missing, region, by = "SiteID")
  to_predict <- merge(missing, phen_all, by = c("SiteID", "Year", "Ordinal"))
  to_predict[, lat := NULL]
  to_predict[, lon := NULL]
  to_predict[, GAM.pred := NULL]
  to_predict$Year <- as.factor(to_predict$Year)
  to_predict$Total <- predict(mod, to_predict, type = "response")
  to_predict$Source <- "EstimGAM_missing"
  
  #new: get GAM estimate for every week to smooth out detection issues
  allweeks <- FillbyWeek(datPop)
  gam_predict <- merge(allweeks, phen_all, by = c("SiteID", "Year", "Ordinal"))
  gam_predict <- data.table(gam_predict)
  gam_predict[, lat := NULL]
  gam_predict[, lon := NULL]
  gam_predict[, GAM.pred := NULL]
  gam_predict$Year <- as.factor(as.character(gam_predict$Year))
  gam_predict$Total <- predict(mod, gam_predict, type = "response")
  gam_predict$Source <- "EstimGAM_allweeks"
  
  datPopPhen <- merge(datPop, phen_all, by = c("SiteID", "Year", "Ordinal"))
  raw <- datPopPhen[, list(Year, Ordinal, SiteID, Week, Total, Gamma)]
  raw$Source <- "RawCount"
  
  allGAMcounts <- rbind(raw, to_predict, gam_predict)
  
  #Get surveys without estimated GAMS
  #UKBMS would interpolate gaps, for now just leave it and let Trapezoidal method average them
  datLinear <- counts[YearTotal >= 3]
#   datLinear[, SitesPerRegion := length(unique(SiteID)), by = list(Region, Year)]
  datLinear <- datLinear[SurvPerYear >= 10]
  datLinear[, SitesObserved := length(unique(SiteID)), by = list(Year)]
  datLinear <- datLinear[SitesObserved < 5]
  datLinear <- datLinear[, list(Year, Ordinal, SiteID, Week, Total)]
  datLinear[,`:=` (Gamma = NA,
                   Source = "LowRawCount")]
  
  #Get surveys with low Totals that year
  datLow <- counts[YearTotal < 3]
  datLow <- datLow[SurvPerYear >= 10]
  datLow <- datLow[, list(Year, Ordinal, SiteID, Week, Total)]
  datLow[,`:=` (Gamma = NA,
                Source = "LowRawCount")]
  
  
  allcounts <- rbind(allGAMcounts, datLinear, datLow)
  #Annual estimates of abundance for site x year
  
  # Try with data.table
  # Pop <- allcounts[, TrpzInd := TrapezoidIndex(Ordinal, Total), by = list(Year, SiteID)]
  # Pop <- Pop[, SumCounts := sum(Total), by = list(Year, SiteID, Source)]
  
  #Try with dplyr
  PopUKBMSTrpz <- allcounts %>% 
    filter(Source != "EstimGAM_allweeks") %>%
    group_by(Year, SiteID) %>%
    summarise(TrpzInd = TrapezoidIndex(Ordinal, Total))
  PopRawTrpz <- allcounts %>%
    filter(Source %in% c("RawCount", "LowRawCount")) %>%
    group_by(Year, SiteID) %>%
    summarise(RawTrpzInd = TrapezoidIndex(Ordinal, Total))
  PopRawSum <- allcounts %>% 
    filter(Source %in% c("RawCount", "LowRawCount")) %>%
    group_by(Year, SiteID) %>%
    summarise(RawSum = sum(Total))
  PopGAMTrpz <- allcounts %>%
    filter(Source == "EstimGAM_allweeks") %>%
    group_by(Year, SiteID) %>%
    summarise(GAMTrpzInd = TrapezoidIndex(Ordinal, Total))
  
  Pops <- merge(PopUKBMSTrpz, PopRawTrpz, by = c("Year", "SiteID"), all = TRUE)
  Pops <- merge(Pops, PopRawSum, by = c("Year", "SiteID"), all = TRUE)
  Pops <- merge(Pops, PopGAMTrpz, by = c("Year", "SiteID"), all = TRUE)
  
  #Collated indices from UKBMS
  PopIndex <- Pops %>%
    filter(RawSum > 0) %>%
    group_by(Year) %>%
    mutate(SitesUsed = length(SiteID)) %>%
    filter(SitesUsed >= 5)
  
  SitesUsed <- PopIndex %>%
    group_by(Year) %>%
    summarise(SitesUsed = length(SiteID))
  
  if(length(unique(PopIndex$Year)) <= 1) next
    
  CollMod <- glm(TrpzInd ~ Year + SiteID - 1, family = poisson(link = "log"), data = PopIndex)
  ALL <- data.frame(cbind("ALL", as.character(SitesUsed$Year), CollMod$coef[1:dim(SitesUsed)[1]], SitesUsed$SitesUsed))
  names(ALL) <- c("Region", "Year", "CollInd", "SitesUsed")
  
  #Collated indices by region
  RegPops <- merge(Pops, region, by = "SiteID")
  
  RegPopIndex <- RegPops %>%
    filter(RawSum > 0) %>%
    group_by(Region, Year) %>%
    mutate(SitesUsed = length(SiteID)) %>%
    filter(SitesUsed >= 2) 
  RegSitesUsed <- RegPopIndex %>%
    group_by(Region, Year) %>%
    summarise(SitesUsed = length(SiteID))
  
  RegIndex <- data.frame()
  regions <- unique(RegPopIndex$Region)
  for (reg in regions){
    temp <- RegPopIndex[Region == reg]
    sites <- RegSitesUsed[Region == reg]
    sites <- arrange(sites, Year)
    sites$Year <- as.numeric(as.character(sites$Year))
    if(length(unique(temp$Year)) < 2){
      out <- data.frame(cbind(reg, sites$Year, NA, sites$SitesUsed))
      }else{
        if(length(unique(temp$SiteID)) < 2){
          out <- data.frame(cbind(reg, sites$Year, NA, sites$SitesUsed))
          }else{
            CollModReg <- glm(TrpzInd ~ Year + SiteID - 1, family = poisson(link = "log"), data = temp)
            out <- data.frame(cbind(reg, sites$Year, CollModReg$coef[1:length(sites$Year)], sites$SitesUsed))
            }
        RegIndex <- rbind(RegIndex, out)
        }
    }
  
  names(RegIndex) <- c("Region", "Year", "CollInd", "SitesUsed")
  RegIndex <- rbind(RegIndex, ALL)
  RegIndex$Year <- as.numeric(as.character(RegIndex$Year))
  RegIndex$CollInd <- as.numeric(as.character(RegIndex$CollInd))
  
  saveRDS(allcounts, file = paste("RDSfiles/allcounts", sp, ".rds", sep = ""))
  saveRDS(phen_all, file = paste("RDSfiles/phenology", sp, ".rds", sep = ""))
  saveRDS(Pops, file = paste("RDSfiles/popsites", sp, ".rds", sep = ""))
  saveRDS(RegIndex, file = paste("RDSfiles/popindex", sp, ".rds", sep = ""))
  
  }

```

NOTE: SOMETHING ABOUT GAM-only POP INDEX is way off.
Only one growth rate estimated for each year. Do not use!!!



Next, get the climate and landuse features sorted out.

Weather:
Just do butterfly sites, not the 1000 random points.
3-month aggregation, quick pca/correlation plot to compare means vs extremes vs el nino/nao
Site-specific anomalies vs all years/sites together for PCA.
Seasonal means/precip vs. PCA by site/year to account for correlation between seasons.

```{r weather features}



library(data.table)
library(lubridate)
library(climdex.pcic)
library(reshape)
library(dplyr)


site_geo <- fread("C:/Users/Tyson/Desktop/Box Sync/Ohio/GIS/OHsites_reconciled.csv", header = TRUE)
site_geo[, SiteID := formatC(as.numeric(Name), width = 3, format = "d", flag = "0")]
setwd("C:/Users/Tyson/Desktop/Box Sync/Ohio/daymet")
source("revised.climdex.functions.R")


#prepare ENSO and NAO to merge with data by season
enso <- read.csv("enso.csv", header = TRUE)
ENSO_clean <- CleanENSO(enso)
nao <- read.delim("monthlyNAO.txt", header = FALSE, sep = "")
NAO_clean <- CleanNAO(nao)
# 
# 
# Daymet4PCA <- function(datafile){
#   source("revised.climdex.functions.R")
# 
#   daymet.file <- paste("sites", datafile, sep = "/")
#   
#   all_content = readLines(daymet.file)
#   skip_lead = all_content[-c(1:6)]
#   data = read.csv(textConnection(skip_lead), header = TRUE, stringsAsFactors = FALSE)
#   
#   data$date <- strptime(paste(data$year, data$yday, sep = " "), format = "%Y %j")
#   data$date <- MoveLeapYears(data$date)
#   data$month <- month(data$date)
#   
#   site <- unlist(strsplit(datafile, "[.]"))[1]
#   site <- unlist(strsplit(site, "e"))[2]
#   data$site <- site
#   data$season <- AddSeasons(data$date)
#   
#   names(data)[3] <- "tmax"
#   names(data)[4] <- "tmin"
#   names(data)[6] <- "prcp"
#   names(data)[8] <- "snow"
#   
#   data <- data[, c("year", "yday", "tmax", "tmin", "prcp", "snow", "date", "month", "site", "season")]
#   
#   clim.input <- climdexInput.Tyson(tmax = data$tmax, tmin = data$tmin, prec = data$prcp,
#                                    tmax.dates = as.PCICt(data$date, "365"), 
#                                    tmin.dates = as.PCICt(data$date, "365"), 
#                                    prec.dates = as.PCICt(data$date, "365"), 
#                                    base.range = c(1980, 2014), n = 5 , northern.hemisphere = TRUE, 
#                                    temp.qtiles = c(.1, .9))
#   
#   #season functions that work
#   meanTemp <- temp.mean(clim.input)
#   dailyTempRange <- season.dtr(clim.input, "season")
#   summerDays <- season.su(clim.input) #tmax > 25
#   summerDays30 <- season.su30(clim.input) #tmax > 30
#   frostDays <- season.fd(clim.input) #tmin < 0
#   icingDays <- season.id(clim.input) #tmax < 0
#   tropNights <- season.tr(clim.input) #tmin > 20
#   totPrecip <- season.prcptot(clim.input) #sum precip >= 1mm
#   lowMinTemp <- season.tn10p(clim.input, "season") #percent of daily minimum temp below 10th percentile
#   highMinTemp <- season.tn90p(clim.input, "season") #percent of daily minimum temp above 90th percentile
#   lowMaxTemp <- season.tx10p(clim.input, "season") #percent of daily maximum temp below 10th percentile
#   highMaxTemp <- season.tx90p(clim.input, "season") #percent of daily maximum temp above 90th percentile
#   warmSpell <- season.wsdi(clim.input, 5, TRUE) #warm spells, consecutive days with tmax > 90th percentile
#   coldSpell <- season.csdi(clim.input, 5, TRUE) #cold spells, consecutive days with tmin < 10th percentile
#   minTmin <- season.tnn(clim.input, "season")
#   maxTmin <- season.tnx(clim.input, "season")
#   minTmax <- season.txn(clim.input, "season")
#   maxTmax <- season.txx(clim.input, "season")
#   drySpell <- season.cdd(clim.input)
#   wetSpell <- season.cwd(clim.input)
#   
#   snowDays <- SeasonSnowDays(data)
#   snowSpell <- SeasonSnowSpell(data)
#   
#   tempFluctDaily <- temp.daily.swing(clim.input, 1)
#   tempFluctWeekly <- temp.daily.swing(clim.input, 7)
#   tempSD <- temp.sd.trend(clim.input)
#   
#   out <- data.frame(site = site, season = rownames(meanTemp), meanTemp, dailyTempRange, summerDays, summerDays30, frostDays, icingDays,
#                     tropNights, totPrecip, lowMinTemp, lowMaxTemp, highMinTemp, highMaxTemp,
#                     warmSpell, coldSpell, minTmin, minTmax, maxTmin, maxTmax, drySpell, wetSpell,
#                     snowDays, snowSpell, tempFluctDaily, tempFluctWeekly, tempSD)
#   return(out)
# }
# 
# 
# #run lapply on all daymet files with function, then rbindlist
# filenames <- as.list(list.files("sites"))
# 
# library(parallel)
# 
# # Calculate the number of cores
# no_cores <- detectCores()-1
#  
# # Initiate cluster
# cl <- makeCluster(no_cores)
# clusterEvalQ(cl, {library(lubridate); library(climdex.pcic); library(reshape); library(dplyr)})
# datList <- parLapply(cl, filenames, Daymet4PCA)
# stopCluster(cl)
# 
# dat <- rbindlist(datList)
# 
# # datList <- lapply(filenames, Daymet4PCA)
# saveRDS(dat, file = "bflysiteDaymet.RDS")

vars <- readRDS("C:/Users/Tyson/Desktop/Box Sync/Ohio/daymet/bflysiteDaymet.rds")
vars[, c("year", "month3") := tstrsplit(as.character(season), "-", fixed = TRUE)][]

# add ENSO and NAO
vars <- merge(vars, ENSO_clean[, -1], by = "season", all.x = TRUE, all.y = FALSE)
vars <- merge(vars, NAO_clean[, -1], by = "season", all.x = TRUE, all.y = FALSE)

# for each year and site
# select appropriate seasons for current summer and previous 4 seasons
years <- c(1995:2014)
weather <- list()

for (i in 1:length(years)){
  yr <- years[i]
  prevspr <- vars[year == (yr - 1)][month3 == "MAM"]
  prevspr <- prevspr[, c(3:5,7,10:27, 30, 31), with = FALSE]
  colnames(prevspr) <- paste("prevspr", colnames(prevspr), sep = "_")
  
  prevsum <- vars[year == (yr-1)][month3 == "JJA"]
  prevsum <- prevsum[, c(3:6,9,10:22,25:27, 30, 31), with = FALSE]
  colnames(prevsum) <- paste("prevsum", colnames(prevsum), sep = "_")
  
  fall <- vars[year == (yr-1)][month3 == "SON"]
  fall <- fall[, c(3:7,10:22,25:27, 30, 31), with = FALSE]
  colnames(fall) <- paste("fall", colnames(fall), sep = "_")
  
  winter <- vars[year == (yr-1)][month3 == "DJF"]
  winter <- winter[, c(3,4,7,8,10:27, 30, 31), with = FALSE]
  colnames(winter) <- paste("winter", colnames(winter), sep = "_")
  
  spring <- vars[year == yr][month3 == "MAM"]
  spring <- spring[, c(3:5,7,10:27, 30, 31), with = FALSE]
  colnames(spring) <- paste("spring", colnames(spring), sep = "_")
  
  currsum <- vars[year == yr][month3 == "JJA"]
  currsum <- currsum[, c(3:6,9,10:22,25:27, 30, 31), with = FALSE]
  colnames(currsum) <- paste("currsum", colnames(currsum), sep = "_")
  
  out <- cbind(prevspr, prevsum, fall, winter, spring, currsum)
  out$year <- yr
  out$site <- unique(vars$site)
  weather[[i]] <- out
}

# boatload of weather variables for each season, 
# so, pairs plot to see highest correlations
# PCA to reduce further (between seasons? or also within seasons?)
allyrweather <- rbindlist(weather)
saveRDS(allyrweather, file = "siteweathervars.RDS")
saveRDS(allyrweather, file = "C:/Users/Tyson/REPO/Chap1-Bfly-Landuse-Climate/data/siteweathervars.RDS")
# 
#correlation matrix!
panel.cor <- function(x, y, digits = 2, cex.cor, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  # correlation coefficient
  r <- cor(x, y)
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste("r= ", txt, sep = "")
  text(0.5, 0.6, txt)

  # p-value calculation
  p <- cor.test(x, y)$p.value
  txt2 <- format(c(p, 0.123456789), digits = digits)[1]
  txt2 <- paste("p= ", txt2, sep = "")
  if(p<0.01) txt2 <- paste("p= ", "<0.01", sep = "")
  text(0.5, 0.4, txt2)
}


vars <- allyrweather[, grep("currsum", names(allyrweather)), with = FALSE]

pairs(vars, upper.panel = panel.cor)

# basically, lesson from pairs plots is that mean temperature correlates with everything temperature
# fluctuations their own thing, but not sure if they matter
# precip it's own thing

pc <- prcomp(vars[, c("currsum_dailyTempRange", "currsum_tempSD", "currsum_drySpell", 
                         "currsum_wetSpell", "currsum_totPrecip", "currsum_tempFluctWeekly",
                         "currsum_tempFluctDaily"), with = FALSE], scale. = TRUE)

pc <- prcomp(vars[, grep("mean|Max|Min|warm|cold", names(vars)), with = FALSE], scale. = TRUE)
pairs(vars[, grep("mean|Max|Min|warm|cold", names(vars)), with = FALSE], upper.panel = panel.cor)



pc_weather <- allyrweather[ ,`:=`(year = NULL, site = NULL)]




pc_temp <- pc_weather[, grep("meanTemp", names(pc_weather)), with = FALSE]
pc_temp_precip <- pc_weather[, grep("meanTemp|totPrecip", names(pc_weather)), with = FALSE]

pc <- prcomp(pc_temp, scale. = TRUE)
pc <- prcomp(pc_temp_precip, scale. = TRUE)


pc_out <- cbind(pc_temp, pc$x, allyrweather[, list(year, site)])
# merge coordinates of random points
DaymetCoords <- function(datafile){
  daymet.file <- paste("randomPts", datafile, sep = "/")
  content = readLines(daymet.file)[1]
  lat <- as.numeric(unlist(strsplit(content, " "))[2])
  lon <- as.numeric(unlist(strsplit(content, " "))[5])
  site <- unlist(strsplit(datafile, "[.]"))[1]
  site <- unlist(strsplit(site, "e"))[2]
  out <- data.frame(site, lat, lon)
  return(out)
}


#run lapply on all daymet files with function, then rbindlist
filenames <- as.list(list.files("randomPts"))
PtCoords <- lapply(filenames, DaymetCoords)
ptcoords <- rbindlist(PtCoords)

pca_coord <- merge(ptcoords, pc_out, by = "site")

library(ggplot2)
library(ggmap)

OHmap <- qmap(location = "Centerburg, OH", zoom = 7)

pca_plot_site <- pca_coord %>%
  group_by(site, lat, lon) %>%
  summarise(mean_pc1 = mean(PC1),
            mean_pc2 = mean(PC2),
            mean_pc3 = mean(PC3),
            mean_pc4 = mean(PC4),
            mean_pc5 = mean(PC5))


OHmap + geom_point(data = pca_plot_site, aes(x = lon, y = lat, colour = mean_pc3), size = 5) + scale_color_gradient()



# what about a pca on the site-level anomalies?
# then include site mean in the lmer model as a covariate of varying slopes

temp_precip <- allyrweather[, grep("meanTemp|totPrecip|year|site|meanENSO|meanNAO", names(allyrweather)), with = FALSE]
temp_precip <- allyrweather[, grep("year|site|meanENSO|meanNAO", names(allyrweather)), with = FALSE]


anomalies <- temp_precip %>%
  group_by(site) %>%
  mutate(
        prevspr_anomTemp = scale(prevspr_meanTemp),
         prevspr_anomPrecip = scale(prevspr_totPrecip),
        prevsum_anomTemp = scale(prevsum_meanTemp),
         prevsum_anomPrecip = scale(prevsum_totPrecip),
         fall_anomTemp = scale(fall_meanTemp),
         fall_anomPrecip = scale(fall_totPrecip),
         winter_anomTemp = scale(winter_meanTemp),
         winter_anomPrecip = scale(winter_totPrecip),
         spring_anomTemp = scale(spring_meanTemp),
         spring_anomPrecip = scale(spring_totPrecip),
         currsum_anomTemp = scale(currsum_meanTemp),
         currsum_anomPrecip = scale(currsum_totPrecip))
anomalies <- anomalies[, grep("anom|year|site", names(anomalies)), with = FALSE]
anomalies <- anomalies[, grep("Temp|year|site", names(anomalies)), with = FALSE]

pc_anom <- anomalies[, `:=`(year = NULL, site = NULL)]

pairs(anomalies[, `:=`(year = NULL, site = NULL)], upper.panel = panel.cor)

anom_pca <- prcomp(pc_anom)


# combine allyrweather with ENSO and NAO, then do PCA

pc_anom_circ <- temp_precip[ ,`:=`(year = NULL, site = NULL)]

test <- prcomp(pc_anom_circ, scale. = TRUE)


```


Landuse:
PCA rather than NMDS for consistency.
Ignore fragmentation/impervious now.
Quantify % change so that it can be ignored.

See package rgr for compositional data, use clr for transformation before PCA.

```{r landuse features}
lulc <- fread("C:/Users/Tyson/REPO/NCEAS-RENCI_2014/Landcover/LC_bflybuff_overtime.csv", header = TRUE)
lulc[, SiteID := formatC(as.numeric(as.character(site)), width = 3, format = "d", flag = "0")]

# 
# 
# luchange <- lulc %>%
#   filter(buffer == 5000) %>%
#   filter(YEAR > 2000) %>%
#   group_by(SiteID, reclass) %>%
#   summarise(PixChange = (total_pix[1] - total_pix[length(total_pix)]))

#convert reclass to vegtype
reclass_table <- data.frame("reclass" = as.character(0:7), "land_cover" = c("nodata", "water", "developed", "barren", "forest", "grassland_shrub", "agriculture", "wetlands"))

#merge conversion table with landcover
landuse <- merge(lulc, reclass_table, by = "reclass")

# remove water and barren landclasses
land_edit <- landuse %>%
  filter(-which(land_cover %in% c("barren", "water")))

landuse_pca <- land_edit %>% 
  filter(YEAR == 2011) %>% 
  filter(buffer == 5000) %>%
  dplyr::select(SiteID, km2, land_cover) %>% 
  spread(land_cover, km2) %>%
  ungroup() %>% group_by(SiteID) %>% 
  mutate(rowtotal = agriculture + developed + forest+ grassland_shrub + wetlands) %>%
  mutate(agriculture_prop = agriculture/rowtotal, 
         developed_prop = developed/rowtotal, 
         forest_prop = forest/rowtotal, 
         grassland_shrub_prop = grassland_shrub/rowtotal,
         wetlands_prop = wetlands/rowtotal) %>% ungroup() 

# use compositional data transformation
library(rgr)
library(vegan)

comp_pca <- clr(as.matrix(landuse_pca[,2:6, with = FALSE] + 1))
mod <- prcomp(comp_pca) # rda or prcomp works too

# plot contours of landuse proportion on pca results
mod.sf <- ordisurf(mod ~ grassland_shrub_prop, data = landuse_pca, plot = FALSE, scaling = 3)
plot(mod.sf, col = "forestgreen")

# save results
# prettyR::delim.table(mod, filename = "lulc_pca_loadings.csv")

# mod 2 PCs explain 80% variation
# PC1 is less ag/more developed as it gets larger
# PC2 is less forest/grassland, more developed as it gets larger
lulc_pc <- data.frame(SiteID = landuse_pca$SiteID, PC1 = scores(mod)[,1], PC2 = scores(mod)[,2], 
                      PC3 = scores(mod)[,3])
saveRDS(lulc_pc, file = "C:/Users/Tyson/REPO/Chap1-Bfly-Landuse-Climate/data/landuse_pca.rds")
```



Notes: 
-check on GAM estimates, might want to only use counts that met requirements to get GAM estimate
LowRawCount is from sites not meeting regional GAM requirements
UKBMS index from EstimGAM_missing + RawCount == TrpzInd in Pops
All GAM estimate is GAMTrpzInd, no GAM interpolations is RawTrpzInd

-split variables by site (landuse and mean temp) and year (weather variable anomalies, ENSO, NAO)
-interactions between site vars and year vars to test climate x landuse
-might be better to have space for time subsitution for weather, where raw weather variables (not anomalies) used
-density dependence debate: lognt1 or site-scaled lognt1 or varying slopes by site (r correlation with intercept weird, though)
-simulation study showed negative correlation between species varying r intercept and dens-dep varying slopes,
opposite of positive correlation in last models of real data

```{r bring in pops, weather, landuse}
SpeciesList <- readRDS("SpeciesList.rds")

# get the 65 species I have population estimates for
allcounts_files <- list.files("RDSfiles", pattern = "allcounts")
species <- unlist(strsplit(allcounts_files, "allcounts", fixed = TRUE))[seq(2,130,2)]
species <- unlist(strsplit(species, "[.]"))[seq(1,129,2)]

allcounts <- list()
phen_all <- list()
Pops <- list()
RegIndex <- list()

for (i in 1:length(species)){
  sp <- species[i]
  allcounts[[i]] <-  cbind(sp, readRDS(file = paste("RDSfiles/allcounts", sp, ".rds", sep = "")))
  phen_all[[i]] <- cbind(sp, readRDS(file = paste("RDSfiles/phenology", sp, ".rds", sep = "")))
  Pops[[i]] <- cbind(sp, readRDS(file = paste("RDSfiles/popsites", sp, ".rds", sep = "")))
  RegIndex[[i]] <- cbind(sp, readRDS(file = paste("RDSfiles/popindex", sp, ".rds", sep = "")))
}

allspcounts <- rbindlist(allcounts)
allspphen <- rbindlist(phen_all)
allspindex <- rbindlist(Pops)
allspregindex <- rbindlist(RegIndex)

allyrweather <- readRDS("data/siteweathervars.RDS")
weather <- allyrweather[, grep("meanTemp|totPrecip|year|site|meanENSO|meanNAO", names(allyrweather)), with = FALSE]
weather[, SiteID := formatC(as.numeric(as.character(site)), width = 3, format = "d", flag = "0")]
weather[, Year := as.character(year)]
weather[, year := NULL]
weather[, site := NULL]

# pca of weather vars over all sites x years
# not that useful, as geographic variation in all seasons temperature is largest component
# also, correlated ENSO between seasons leads to its clustering in one PC

pc_temp <- weather[, grep("meanTemp", names(weather)), with = FALSE]
pc_temp_precip <- weather[, grep("meanTemp|totPrecip", names(weather)), with = FALSE]
pc_temp_precip_circ <- weather[, grep("mean|totPrecip", names(weather)), with = FALSE]
pc_temp_circ <- weather[, grep("mean", names(weather)), with = FALSE]

pca_temp <- prcomp(pc_temp, scale. = TRUE)
pca_temp_precip <- prcomp(pc_temp_precip, scale. = TRUE)
pca_temp_precip_circ <- prcomp(pc_temp_precip_circ, scale. = TRUE)
pca_temp_circ <- prcomp(pc_temp_circ, scale. = TRUE)




# scale weather vars over all sites x years
weathercols <- names(weather)[1:24]
anomcols <- names(weather)[grep("meanTemp|totPrecip", names(weather))]

weather[ , (paste("z", weathercols, sep = "_")) := as.data.table(scale(.SD)), .SDcols = weathercols]

# scale weather vars by site-level anomalies
weather[, (paste("siteanom", anomcols, sep = "_")) := as.data.table(scale(.SD)), .SDcols = anomcols, by = SiteID]

# mean site conditions
sitecols <- paste("z", anomcols, sep = "_")
weather[, (paste("sitemean", sitecols, sep = "_")) := lapply(.SD, mean), .SDcols = sitecols, by = SiteID]

# orthogonal squared weather over all sites x years
sqpoly <- function(x){
  temp <- poly(x, degree = 2)
  return(temp[,2])
}

weather[ , (paste("zsq", weathercols, sep = "_")) := lapply(.SD, sqpoly), .SDcols = weathercols]

# pca of anomalies of sites
# weather <- weather[, grep("siteanom|NAO|ENSO", names(weather)), with = FALSE]

pc_temp <- weather[, grep("meanTemp", names(weather)), with = FALSE]
pc_temp_precip <- weather[, grep("meanTemp|totPrecip", names(weather)), with = FALSE]
pc_temp_precip_circ <- weather[, grep("mean|totPrecip", names(weather)), with = FALSE]
pc_temp_circ <- weather[, grep("mean", names(weather)), with = FALSE]
pc_anom <- pc_temp[, grep("anom", names(pc_temp)), with = FALSE]

pca_temp <- prcomp(pc_temp, scale. = TRUE)
pca_temp_precip <- prcomp(pc_temp_precip, scale. = TRUE)
pca_temp_precip_circ <- prcomp(pc_temp_precip_circ, scale. = TRUE)
pca_temp_circ <- prcomp(pc_temp_circ, scale. = TRUE)

pca_anom <- prcomp(pc_anom, scale. = TRUE)





# check that means make sense
# site mean same for all rows, mean anomalies are 0, z scores mean not zero
summary(weather[SiteID == "001"])

allspindex$Year <- as.character(allspindex$Year)
allspindex$SiteID <- as.character(allspindex$SiteID)

lulc_pc <- readRDS("data/landuse_pca.rds")
lulc_pc$SiteID <- as.character(lulc_pc$SiteID)

dat <- merge(allspindex, weather, by = c("SiteID", "Year"))
dat <- merge(dat, lulc_pc, by = "SiteID")

saveRDS(dat, file = "modelingData.rds")

```

Make growth rate response variables and lagged density dependence.

```{r response}
library(lme4)

dat <- readRDS("modelingData.rds")

# add previous year lag for density dependence
dat$Year <- as.numeric(dat$Year)
dat$SpSiteID <- paste(dat$sp, dat$SiteID, sep = "_")

# dumb switch between data.table and dplyr

expanddat <- dplyr::select(dat, SpSiteID, Year, TrpzInd, RawTrpzInd, RawSum, GAMTrpzInd)

expanddat <- expanddat %>%
  tidyr::expand(SpSiteID, Year) %>%
  dplyr::left_join(expanddat)

newdat <- 
    expanddat %>%
    arrange(SpSiteID, Year) %>%
    group_by(SpSiteID) %>%
    mutate(lag.TrpzInd = lag(TrpzInd, 1),
           lag.RawTrpzInd = lag(RawTrpzInd, 1),
           lag.RawSum = lag(RawSum, 1),
           lag.GAMTrpzInd = lag(GAMTrpzInd, 1))

# get growth rates for response variables
# for now, use log(n + 1) to deal with zeros
# also, site scaled lag N will not worry about zeros (but not in growth rate response)
# GAMTrpzInd will not have that issue, only has estimates for counts >= 3

response <- newdat %>%
  filter(RawSum > 0 & lag.RawSum > 0) %>%
  mutate(growth_ukbms_add1 = log((TrpzInd + 1) / (lag.TrpzInd + 1)),
         growth_ukbms_NAzero = log(TrpzInd/lag.TrpzInd),
         growth_rawtrpz_add1 = log((RawTrpzInd + 1) / (lag.RawTrpzInd + 1)),
         growth_rawtrpz_NAzero = log(RawTrpzInd/lag.RawTrpzInd),
         growth_rawsum_add1 = log((RawSum + 1) / (lag.RawSum + 1)),
         growth_rawsum_NAzero = log(RawSum/lag.RawSum),
         growth_gam = log(GAMTrpzInd/lag.GAMTrpzInd))

response <- data.table(response)
invisible(lapply(names(response),function(.name) set(response, which(is.infinite(response[[.name]])), j = .name,value =NA)))

# density dependence at the site (not just lag-1 abundance)
response <- response %>%
  group_by(SpSiteID) %>%
  mutate(ddsite_ukbms = scale(lag.TrpzInd),
         ddsite_rawtrpz = scale(lag.RawTrpzInd),
         ddsite_rawsum = scale(lag.RawSum),
         ddsite_gam = scale(lag.GAMTrpzInd))
# problem with ddsite = 0 when not enough observations at a site to scale
# assign these to zero, give no information if at mean of covariate
invisible(lapply(names(response)[grep("ddsite", x = names(response))], function(.name) 
  set(response, which(is.na(response[[.name]])), j = .name, value = 0)))

datmod <- merge(response, dat, by = c("SpSiteID", "Year", "TrpzInd", "RawTrpzInd", "RawSum", "GAMTrpzInd"))



```


model that shit

85 variables in datmod, many redundant.

1st attempt:
All 5 seasons linear and orthogonal squared temperature. 
All varying slopes by species.
Can't fit, try with allFit function to try all optimizers.
For m2, weird random effects, squared terms especially large variance.
Could be due to orthogonal or lack of convergence in fitting.
Also, tried this with 65 species, some of which only had 20 observations. Filter these!!

2nd attempt:
Non-orthogonal quadratic effects of weather with 39 species.
Bobyqa fits it OK, little RE correlation. 
Great spangled fritillary has extreme random effects, possibly a bad sign for model fit.


3rd:
PCA of 5 seasons temperature variables to try and reduce ##?
Or just reduce model random effects by doing single species models?


```{r model}

datmod$YearFact <- as.factor(datmod$Year)
datmod <- datmod %>%
  rowwise() %>%
  dplyr::mutate(meantemp = mean(c(sitemean_z_fall_meanTemp,
                        sitemean_z_winter_meanTemp,
                        sitemean_z_spring_meanTemp,
                        sitemean_z_prevsum_meanTemp))) 

datmodcut <- datmod %>%
  group_by(sp) %>%
  dplyr::mutate(numobs = length(growth_ukbms_add1)) %>%
  filter(numobs > 140)






test.formula3 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp + 
                    zsq_currsum_meanTemp + 
                    zsq_spring_meanTemp + 
                    zsq_winter_meanTemp + 
                    zsq_fall_meanTemp +  
                    zsq_prevsum_meanTemp + 
                (1 + ddsite_ukbms +  z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp + 
                    zsq_currsum_meanTemp + 
                    zsq_spring_meanTemp + 
                    zsq_winter_meanTemp + 
                    zsq_fall_meanTemp +  
                    zsq_prevsum_meanTemp| sp))



form3 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp + 
                    I(z_currsum_meanTemp^2) + 
                    I(z_spring_meanTemp^2) + 
                    I(z_winter_meanTemp^2) + 
                    I(z_fall_meanTemp^2) +  
                    I(z_prevsum_meanTemp^2) + 
                (1 + ddsite_ukbms +  z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp + 
                   I(z_currsum_meanTemp^2) + 
                    I(z_spring_meanTemp^2) + 
                    I(z_winter_meanTemp^2) + 
                    I(z_fall_meanTemp^2) +  
                    I(z_prevsum_meanTemp^2)| sp))



library(nloptr)
defaultControl <- list(algorithm="NLOPT_LN_BOBYQA",xtol_rel=1e-6,maxeval=1e6)
nloptwrap2 <- function(fn,par,lower,upper,control=list(),...) {
    for (n in names(defaultControl)) 
      if (is.null(control[[n]])) control[[n]] <- defaultControl[[n]]
    res <- nloptr(x0=par,eval_f=fn,lb=lower,ub=upper,opts=control,...)
    with(res,list(par=solution,
                  fval=objective,
                  feval=iterations,
                  conv=if (status>0) 0 else status,
                  message=message))
}

system.time(test.model <- lmer(test.formula, data=datmod,
control=lmerControl(optimizer="nloptwrap2")))

system.time(test.model2 <- lmer(test.formula2, data=datmod,
control=lmerControl(optimizer="nloptwrap2")))


system.time(model3 <- lmer(form3, data=datmodcut,
control=lmerControl(optimizer="nloptwrap2")))


mod <- readRDS("lmerModallseasons.RDS")
ss <- getME(mod,c("theta","fixef"))
m2 <- update(mod,start=ss,control=lmerControl(optimizer = "nloptwrap2"))
ss2 <- getME(mod,c("theta","fixef"))
m3 <- update(m2,start=ss2,control=lmerControl(optimizer = "nloptwrap2"))

source('optimizers.R')
  mods <- allFit(lmer(form3, data = datmodcut), 
                 meth.tab = cbind(optimizer=
                                         rep(c("bobyqa","Nelder_Mead", "optimx",  "nloptWrap"),
                                             c(    1,         1,           2,         2)),
                                       method= c("",        "",  "nlminb","L-BFGS-B",
                                                 "NLOPT_LN_NELDERMEAD", "NLOPT_LN_BOBYQA")),
                   verbose=TRUE,
                   
                   maxfun=2e5)

  aa <- mods
  is.OK <- sapply(aa,is,"merMod")  ## nlopt NELDERMEAD failed, others succeeded
aa.OK <- aa[is.OK]
lapply(aa.OK,function(x) x@optinfo$conv$lme4$messages)
  (lliks <- sort(sapply(aa.OK,logLik)))
  
aa.fixef <- t(sapply(aa.OK,fixef))
aa.fixef.m <- melt(aa.fixef)
models <- levels(aa.fixef.m$Var1)
ylabs <- substr(models,1,3)
aa.fixef.m <- transform(aa.fixef.m,Var1=factor(Var1,levels=names(lliks)))
(gplot1 <- ggplot(aa.fixef.m,aes(x=value,y=Var1,colour=Var1))+geom_point()+
     facet_wrap(~Var2,scale="free")+
         scale_colour_brewer(palette="Dark2")+
             scale_y_discrete(breaks=models,
                              labels=ylabs)+
                                  labs(x="",y=""))

saveRDS(mods, "allfitlmerallseasons.RDS")

mods <- readRDS("allfitlmerallseasons.RDS")



# single species model
datsp <- datmod %>% filter(sp == "Spicebush Swallowtail")


form.sp <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp + 
                    I(z_currsum_meanTemp^2) + 
                    I(z_spring_meanTemp^2) + 
                    I(z_winter_meanTemp^2) + 
                    I(z_fall_meanTemp^2) +  
                    I(z_prevsum_meanTemp^2) 
                )

spmod <- lm(form.sp, data = datsp)


form.sp1 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp + 
                    I(z_currsum_meanTemp^2) + 
                    I(z_spring_meanTemp^2) + 
                    I(z_winter_meanTemp^2) + 
                    I(z_fall_meanTemp^2) +  
                    I(z_prevsum_meanTemp^2) + 
                      (1|SiteID))

form.sp2 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp + 
                    I(siteanom_currsum_meanTemp^2) + 
                    I(siteanom_spring_meanTemp^2) + 
                    I(siteanom_winter_meanTemp^2) + 
                    I(siteanom_fall_meanTemp^2) +  
                    I(siteanom_prevsum_meanTemp^2) + 
                      (1|SiteID))


form.sp1 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    z_currsum_meanTemp + 
                    z_prevsum_meanTemp + 
                    I(z_currsum_meanTemp^2) + 
                    I(z_prevsum_meanTemp^2) + 
                      (1|SiteID))

form.sp2 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    z_currsum_meanTemp + 
                    z_prevsum_meanTemp + 
                    I(z_currsum_meanTemp^2) + 
                    I(z_prevsum_meanTemp^2) )


form.sp3 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    siteanom_currsum_meanTemp + 
                    siteanom_prevsum_meanTemp + 
                    I(siteanom_currsum_meanTemp^2) + 
                    I(siteanom_prevsum_meanTemp^2) + 
                    sitemean_z_currsum_meanTemp + 
                    sitemean_z_prevsum_meanTemp + 
                    I(sitemean_z_currsum_meanTemp^2) + 
                    I(sitemean_z_prevsum_meanTemp^2) )

form.sp4 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    siteanom_currsum_meanTemp + 
                    siteanom_prevsum_meanTemp + 
                    I(siteanom_currsum_meanTemp^2) + 
                    I(siteanom_prevsum_meanTemp^2) )

form.sp5 <- as.formula(growth_ukbms_add1 ~ 
                                ddsite_ukbms +  
                    siteanom_currsum_meanTemp*sitemean_z_currsum_meanTemp + 
                    siteanom_prevsum_meanTemp*sitemean_z_prevsum_meanTemp  + 
                    I(siteanom_currsum_meanTemp^2) + 
                    I(siteanom_prevsum_meanTemp^2) )

form.sp6 <- as.formula(growth_ukbms_add1 ~ 
                      ddsite_ukbms +  
                      meantemp +
                      siteanom_currsum_meanTemp +
                      siteanom_currsum_meanTemp : meantemp  +
                      siteanom_prevsum_meanTemp +
                      siteanom_prevsum_meanTemp : meantemp  
                      )
form.sp6re <- as.formula(growth_ukbms_add1 ~ 
                      ddsite_ukbms +  
                      meantemp +
                      siteanom_currsum_meanTemp +
                      siteanom_currsum_meanTemp : meantemp  +
                      siteanom_prevsum_meanTemp +
                      siteanom_prevsum_meanTemp : meantemp  +
                        (1|YearFact)
                      )

                     
   
                     
      form.sp7 <- as.formula(growth_ukbms_add1 ~ 
                      ddsite_ukbms +  
                      meantemp +
                      siteanom_currsum_meanTemp +
                      siteanom_currsum_meanTemp : meantemp  +
                      siteanom_prevsum_meanTemp +
                      siteanom_prevsum_meanTemp : meantemp +
                      I(siteanom_currsum_meanTemp^2) +
                      I(siteanom_currsum_meanTemp^2) : meantemp  +
                      I(siteanom_prevsum_meanTemp^2) +
                      I(siteanom_prevsum_meanTemp^2) : meantemp +
                      siteanom_spring_meanTemp +
                      siteanom_spring_meanTemp : meantemp +
                      I(siteanom_spring_meanTemp^2) +
                      I(siteanom_spring_meanTemp^2) : meantemp+
                      siteanom_winter_meanTemp +
                      siteanom_winter_meanTemp : meantemp +
                      I(siteanom_winter_meanTemp^2) +
                      I(siteanom_winter_meanTemp^2) : meantemp +
                        siteanom_fall_meanTemp +
                      siteanom_fall_meanTemp : meantemp +
                      I(siteanom_fall_meanTemp^2) +
                      I(siteanom_fall_meanTemp^2) : meantemp 
                      )                  
           
  



mod1 <- lmer(form.sp1, data = datsp)
mod2 <- lm(form.sp2, data = datsp)
mod3 <- lm(form.sp3, data = datsp)
mod4 <- lm(form.sp4, data = datsp)
mod5 <- lm(form.sp5, data = datsp)
mod6 <- lm(form.sp6, data = datsp)
mod6re <- lmer(form.sp6re, data = datsp)
mod7 <- lm(form.sp7, data = datsp)

library(tree)
tree.form <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp  
                   )
tree.mod <- tree(tree.form, datsp)

tree.form.anom <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp  
                   )
tree.mod.anom <- tree(tree.form.anom, datsp)

library(mgcv)
gam.mod <- gam(growth_ukbms_add1 ~ 
                    s(ddsite_ukbms) +  
                    s(z_currsum_meanTemp) + 
                    s(z_spring_meanTemp) + 
                    s(z_winter_meanTemp) + 
                    s(z_fall_meanTemp) +  
                    s(z_prevsum_meanTemp), data = datsp)


gam.mod.anom <- gam(growth_ukbms_add1 ~ 
                    s(ddsite_ukbms) +  
                    s(siteanom_currsum_meanTemp) + 
                    s(siteanom_spring_meanTemp) + 
                    s(siteanom_winter_meanTemp) + 
                    s(siteanom_fall_meanTemp) +  
                    s(siteanom_prevsum_meanTemp), data = datsp)


saturated <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms +  
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp + 
                    I(z_currsum_meanTemp^2) + 
                    I(z_spring_meanTemp^2) + 
                    I(z_winter_meanTemp^2) + 
                    I(z_fall_meanTemp^2) +  
                    I(z_prevsum_meanTemp^2) +
                      meantemp)

mod <- lm(form.sp7, datsp)
stmod <- step(mod)
options(na.action = "na.fail")   #  prevent fitting models to different datasets
drmod <- dredge(mod, beta = "none", fixed = "ddsite_ukbms", m.lim = c(2, 5))

library(caret)

ctrl <- rfeControl(functions = lmFuncs,
                   method = "repeatedcv",
                   repeats = 5,
                   verbose = FALSE)
subsets <- c(1:10)
x <- datsp %>%
  dplyr::select(c(18, 43 +grep("Temp|totPrecip", names(datsp)[44:63])))
y <- datsp$growth_ukbms_add1

lmProfile <- rfe(x, y,
                 sizes = subsets,
                 rfeControl = ctrl)

lmProfile
```

Odd feature of model:
Single-species models give different variables that are most important.
Also, when random effect for year included, important variables change.
Does not inspire much confidence.
Possibly try the anomalies x site mean conditions as a way.
Perhaps treating temperature as global effect without regard to context not good.




Use spatial leave one out.
Will select fewer variables than AIC or LOO.
Use this fact to narrow down models.
Use step to backwards selection down to manageable # of parameters, then
use SLOO to reduce further based on spatial grain (also leave out year of observation)



```{r model selection}

datmod$YearFact <- as.factor(datmod$Year)
datmod <- datmod %>%
  rowwise() %>%
  dplyr::mutate(meantemp = mean(c(sitemean_z_fall_meanTemp,
                        sitemean_z_winter_meanTemp,
                        sitemean_z_spring_meanTemp,
                        sitemean_z_prevsum_meanTemp))) 

datmodcut <- datmod %>%
  group_by(sp) %>%
  dplyr::mutate(numobs = length(growth_ukbms_add1)) %>%
  filter(numobs > 140)



spec <- "Spicebush Swallowtail"

datsp <- datmodcut %>% filter(sp == spec) 

# plot temperature variables vs growth rate correlation
pairs(datsp[ , c("z_currsum_meanTemp", 
                   "z_spring_meanTemp", 
                   "z_winter_meanTemp",  
                   "z_fall_meanTemp",  
                   "z_prevsum_meanTemp", "growth_ukbms_add1")], panel = panel.smooth)

pairs(datsp[ , c("siteanom_currsum_meanTemp", 
                   "siteanom_spring_meanTemp", 
                   "siteanom_winter_meanTemp",  
                   "siteanom_fall_meanTemp",  
                   "siteanom_prevsum_meanTemp", "growth_ukbms_add1")], panel = panel.smooth)

library(ggplot2)
a <- ggplot(data = datsp, aes(x = jitter(Year), y = growth_ukbms_add1, group = meantemp, color = meantemp)) + 
  geom_point(size = 5) + theme_bw() + scale_color_continuous(low = "blue", high = "red")
a

# 
# %>%
#   dplyr::select(growth_ukbms_add1, ddsite_ukbms, siteanom_prevsum_meanTemp, siteanom_prevsum_totPrecip,
#          siteanom_fall_meanTemp, siteanom_fall_totPrecip, siteanom_winter_meanTemp,
#          siteanom_winter_totPrecip, siteanom_spring_meanTemp, siteanom_spring_totPrecip,
#          siteanom_currsum_meanTemp, siteanom_currsum_totPrecip, YearFact, meantemp, PC1, PC2, numobs)
clim.form000a <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp + 
                    z_prevspr_meanTemp)

clim.form000b <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp)

clim.form00a <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp +
                    I(z_currsum_meanTemp^2) + 
                    I(z_spring_meanTemp^2) + 
                    I(z_winter_meanTemp^2) + 
                    I(z_fall_meanTemp^2) +  
                    I(z_prevsum_meanTemp^2))

clim.form00b <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp + 
                    I(siteanom_currsum_meanTemp^2) + 
                    I(siteanom_spring_meanTemp^2) + 
                    I(siteanom_winter_meanTemp^2) + 
                    I(siteanom_fall_meanTemp^2) +  
                    I(siteanom_prevsum_meanTemp^2))
                    
clim.form0 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp +
                    meantemp +
                    meantemp:z_currsum_meanTemp + 
                    meantemp:z_spring_meanTemp + 
                    meantemp:z_winter_meanTemp + 
                    meantemp:z_fall_meanTemp +  
                    meantemp:z_prevsum_meanTemp)

clim.form1 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp +
                    meantemp +
                    meantemp:siteanom_currsum_meanTemp + 
                    meantemp:siteanom_spring_meanTemp + 
                    meantemp:siteanom_winter_meanTemp + 
                    meantemp:siteanom_fall_meanTemp +  
                    meantemp:siteanom_prevsum_meanTemp)

clim.form2 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp +
                      I(z_currsum_meanTemp^2) + 
                   I(z_spring_meanTemp^2) + 
                   I(z_winter_meanTemp^2) + 
                    I(z_fall_meanTemp^2) +  
                    I(z_prevsum_meanTemp^2) +
                    meantemp +
                    meantemp:z_currsum_meanTemp + 
                    meantemp:z_spring_meanTemp + 
                    meantemp:z_winter_meanTemp + 
                    meantemp:z_fall_meanTemp +  
                    meantemp:z_prevsum_meanTemp +
                    meantemp:I(z_currsum_meanTemp^2) + 
                    meantemp:I(z_spring_meanTemp^2) + 
                    meantemp:I(z_winter_meanTemp^2) + 
                    meantemp:I(z_fall_meanTemp^2) +  
                    meantemp:I(z_prevsum_meanTemp^2))


clim.form3 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp +
                    I(siteanom_currsum_meanTemp^2) + 
                    I(siteanom_spring_meanTemp^2) + 
                    I(siteanom_winter_meanTemp^2) + 
                    I(siteanom_fall_meanTemp^2) +  
                    I(siteanom_prevsum_meanTemp^2) +
                    meantemp +
                    meantemp:siteanom_currsum_meanTemp + 
                    meantemp:siteanom_spring_meanTemp + 
                    meantemp:siteanom_winter_meanTemp + 
                    meantemp:siteanom_fall_meanTemp +  
                    meantemp:siteanom_prevsum_meanTemp +
                      meantemp:I(siteanom_currsum_meanTemp^2) + 
                    meantemp:I(siteanom_spring_meanTemp^2) + 
                    meantemp:I(siteanom_winter_meanTemp^2) + 
                    meantemp:I(siteanom_fall_meanTemp^2) +  
                    meantemp:I(siteanom_prevsum_meanTemp^2))

mod00a <- lm(clim.form00a, datsp)
mod00b <- lm(clim.form00b, datsp)
mod000a <- lm(clim.form000a, datsp)
mod000b <- lm(clim.form000b, datsp)

mod0 <- lm(clim.form0, datsp)
mod1 <- lm(clim.form1, datsp)
mod2 <- lm(clim.form2, datsp)
mod3 <- lm(clim.form3, datsp)

stmod00a <- step(mod00a)
stmod00b <- step(mod00b)
stmod000a <- step(mod000a)
stmod000b <- step(mod000b)
stmod0 <- step(mod0)
stmod1 <- step(mod1)
stmod2 <- step(mod2)
stmod3 <- step(mod3)


AIC(mod000a, mod000b, mod00a, mod00b, mod0, mod1, mod2, mod3)
AIC(stmod000a, stmod000b, stmod00a, stmod00b, stmod0, stmod1, stmod2, stmod3)
model.sel(mod000a, mod000b, mod00a, mod00b, mod0, mod1, mod2, mod3) # mod1 clear winner here
model.sel(stmod000a, stmod000b, stmod00a, stmod00b, stmod0, stmod1, stmod2, stmod3) #stmod3 wins


options(na.action = "na.fail")   #  prevent fitting models to different datasets

drmod0 <- dredge(mod0, evaluate = TRUE, m.lim = c(1, 6))
drmod1 <- dredge(mod1, evaluate = TRUE, m.lim = c(1, 6))
drmod2 <- dredge(mod2, evaluate = TRUE, m.lim = c(1, 6))
drmod3 <- dredge(mod3, evaluate = TRUE, m.lim = c(1, 6))

model.sel(get.models(drmod3, delta < 4))
model.sel(get.models(drmod0, subset = 1)[[1]], get.models(drmod1, subset = 1)[[1]],
          get.models(drmod2, subset = 1)[[1]], get.models(drmod3, subset = 1)[[1]])

# step and dredge results
summary(stmod0)
summary(get.models(drmod0, subset = 1)[[1]])

summary(stmod1)
summary(get.models(drmod1, subset = 1)[[1]])

summary(stmod2)
summary(get.models(drmod2, subset = 1)[[1]])

summary(stmod3)
summary(get.models(drmod3, subset = 1)[[1]])
# plot interactions

sjp.int(stmod2, type = "eff", int.term = "z_fall_meanTemp")  
sjp.lm(stmod2, type = "poly", poly.term = "z_spring_meanTemp")



# weird currsum/prevsum contradiction
# what if only use every other year?

clim.form0 <- as.formula(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    scale(Year) +
                    I(ddsite_ukbms^2) +
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp +
                    meantemp +
                    meantemp:z_currsum_meanTemp + 
                    meantemp:z_spring_meanTemp + 
                    meantemp:z_winter_meanTemp + 
                    meantemp:z_fall_meanTemp +  
                    meantemp:z_prevsum_meanTemp)


mod.even <- lm(clim.form0, data = datsp[which(datsp$Year %% 2 == 0), ])

mod.odd <- lm(clim.form0, data = datsp[which(datsp$Year %% 2 == 1), ])

mod.all <- lm(clim.form0, data = datsp)
stmod <- step(mod.all)

mod.re <- lmer(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    scale(Year) +
                    I(ddsite_ukbms^2) +
                    z_currsum_meanTemp + 
                    z_spring_meanTemp + 
                    z_winter_meanTemp + 
                    z_fall_meanTemp +  
                    z_prevsum_meanTemp +
                    meantemp +
                    meantemp:z_currsum_meanTemp + 
                    meantemp:z_spring_meanTemp + 
                    meantemp:z_winter_meanTemp + 
                    meantemp:z_fall_meanTemp +  
                    meantemp:z_prevsum_meanTemp +
               (1|YearFact), data = datsp)

mod.null <- lm(growth_ukbms_add1 ~ 
                    ddsite_ukbms + 
                    I(ddsite_ukbms^2), data = datsp)

# plot
a <- ggplot(data = datsp, aes(x = year))



```



Right now, my inclination is use simple linear models (no random effects).
1. Start with simple models and increase in complexity to climate x landuse.
2. Spatiotemporal leave one out CV to select variables in models with backwards selection -> prediction as goal in this study. This leaves issue of scale in variogram for each species.
3. Once top models selected, maybe then use hierarchical partitioning to give importance of climate vs landuse vs density dependence.
4. Traits come in at the end.


Still unresolved: PCA of climate anomalies or not. Maybe reduce 6 seasons to 3-4 PCs.
1st PC is correlated with warm years for all seasons.


```{r stloo}

datmod$YearFact <- as.factor(datmod$Year)
sitemeans <- readRDS("data/sitemeans.rds")

datmod2 <- merge(datmod, sitemeans[, c("zmean", "SiteID"), with = FALSE], by = "SiteID")

datmodcut <- datmod2 %>%
  group_by(sp) %>%
  dplyr::mutate(numobs = length(growth_ukbms_add1)) %>%
  filter(numobs > 140)

spec <- "Least Skipper"

datsp <- datmodcut %>% filter(sp == spec) 
# 
# mod.null1 <- lm(growth_ukbms_add1 ~ 
#                     ddsite_ukbms + 
#                     I(ddsite_ukbms^2), data = datsp)
# mod.null2 <- lm(growth_ukbms_add1 ~ 
#                     log(lag.TrpzInd) + 
#                     I(log(lag.TrpzInd)^2), data = datsp)
# 
# # basic density dependence
# plot(datsp$ddsite_ukbms, datsp$growth_ukbms_add1)
# plot(datsp$lag.TrpzInd, datsp$growth_ukbms_add1)



site_geo <- fread("C:/Users/Tyson/Desktop/Box Sync/Ohio/GIS/OHsites_reconciled.csv", header = TRUE)
site_geo[, SiteID := formatC(as.numeric(Name), width = 3, format = "d", flag = "0")]

# problem with spatial analysis when sites have same coordinates
# duplat <- site_geo[duplicated(site_geo[, c("lat", "lon"), with = FALSE])]$lat
# duplon <- site_geo[duplicated(site_geo[, c("lat", "lon"), with = FALSE])]$lon
# dupsites <- site_geo[lat %in% duplat & lon %in% duplon]

# jitter coordinates slightly
site_geo$lat <- site_geo$lat + rnorm(length(site_geo$lat), mean = 0, sd = 0.0001)
site_geo$lon <- site_geo$lon + rnorm(length(site_geo$lon), mean = 0, sd = 0.0001)


datsp <- merge(datsp, site_geo[, c("SiteID", "lat", "lon"), with = FALSE], by = "SiteID")

# 
# mod.null1 <- lm(growth_ukbms_add1 ~ 
#                     ddsite_ukbms + 
#                     I(ddsite_ukbms^2), data = datsp)
# 
# 
# # Spatial-temporal Leave One Out
# 
# m1 <- glm(growth_ukbms_add1 ~ 1, data = datsp, family = gaussian)
# m2 <- glm(growth_ukbms_add1 ~ ddsite_ukbms, data = datsp, family = gaussian)
# m3 <- glm(growth_ukbms_add1 ~ 
#                     ddsite_ukbms + 
#                     I(ddsite_ukbms^2), data = datsp, family = gaussian)
# m4 <- glm(growth_ukbms_add1 ~ 
#                     ddsite_ukbms + 
#                     I(ddsite_ukbms^2) +
#                     siteanom_currsum_meanTemp + 
#                     siteanom_spring_meanTemp + 
#                     siteanom_winter_meanTemp + 
#                     siteanom_fall_meanTemp +  
#                     siteanom_prevsum_meanTemp +
#                     zmean, data = datsp, family = gaussian)
# m5 <- glm(growth_ukbms_add1 ~ 
#                     ddsite_ukbms + 
#                     I(ddsite_ukbms^2) +
#                     siteanom_currsum_meanTemp + 
#                     siteanom_spring_meanTemp + 
#                     siteanom_winter_meanTemp + 
#                     siteanom_fall_meanTemp +  
#                     siteanom_prevsum_meanTemp +
#                     siteanom_prevspr_meanTemp +
#                     zmean +
#                     zmean:siteanom_currsum_meanTemp + 
#                     zmean:siteanom_spring_meanTemp + 
#                     zmean:siteanom_winter_meanTemp + 
#                     zmean:siteanom_fall_meanTemp +  
#                     zmean:siteanom_prevsum_meanTemp +
#                     zmean:siteanom_prevspr_meanTemp, data = datsp, family = gaussian)

# library(Imap)
# # What is the ideal splitting distance?
# dists <- dist(datsp[, c("lat", "lon"), with = FALSE])
# dists_km <- round(GeoDistanceInMetresMatrix(as.data.frame(datsp[, c("lat", "lon"), with = FALSE])) / 1000)
# df.sites <- as.data.frame(site_geo[, c("lat", "lon"), with = FALSE])
# dists_meter <- GeoDistanceInMetresMatrix(df.sites)
# summary(dists)
# dists_km <- round(dists_meter/1000)

datsp <- as.data.frame(datsp)
datspmod <- datsp[, c("lat", "lon", "PC1", "PC2", "SiteID", "Year", "YearFact", "sp",
                      "growth_ukbms_add1",
                      "ddsite_ukbms",
                      "siteanom_currsum_meanTemp",
                      "siteanom_spring_meanTemp",
                      "siteanom_winter_meanTemp",
                      "siteanom_fall_meanTemp",
                      "siteanom_prevsum_meanTemp",
                      "siteanom_prevspr_meanTemp",
                      "zmean")]
datspmod$ddsite_ukbms_square <- I(datspmod$ddsite_ukbms^2)

m5int <- glm(growth_ukbms_add1 ~ ddsite_ukbms +
               ddsite_ukbms_square + 
               (zmean + siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp +
                    siteanom_prevspr_meanTemp)^2, 
             data = datspmod, family = gaussian)
# 
# m5exp <- gls(growth_ukbms_add1 ~ ddsite_ukbms +
#                ddsite_ukbms_square +
#                (zmean + siteanom_currsum_meanTemp +
#                     siteanom_spring_meanTemp +
#                     siteanom_winter_meanTemp +
#                     siteanom_fall_meanTemp +
#                     siteanom_prevsum_meanTemp +
#                     siteanom_prevspr_meanTemp)^2,
#              correlation = corExp(form = ~lon + lat, nugget = TRUE),
#              data = datspmod)



source('spatiotempLOO.R')
rsa <- seq(0, .5 , .05) #residual spatial autocorrelation
training.sets <- list()
test <- list()
model <- m5int
for (i in 1:length(rsa)){
  training.sets[[i]] <- splittingST(data = datspmod, 
                               lon.lab="lon",
                               lat.lab="lat",
                               yr.lab = "Year",
                               dist.split=rsa[i],
                               time.split = 1)
  test[[i]] <- modSelect(full.mod = model, training = training.sets[[i]], steps = 50)

}

results <- data.frame()
  for (m in 1:length(test)){
    temp <- data.frame(model = m, rsa = rsa[m], loglik = test[[m]]$loglik, npar = length(coef(test[[m]]$fit)), aic = test[[m]]$AIC)
    results <- rbind(results, temp)
    # names(results) <- c("model", "rsa", "loglik", "npar", "AIC")
  }

# make stloo fitting a parallel function
rsa <- as.list(seq(0, .5 , .05)) #residual spatial autocorrelation

fitstloo <- function(rsa, model){
  # source("spatiotempLOO.R")
  training.sets <- list()
  test <- list()
  training.sets <- splittingST(data = model$data, 
                               lon.lab="lon",
                               lat.lab="lat",
                               yr.lab = "Year",
                               dist.split=rsa,
                               time.split = 1)
  test <- modSelect(full.mod = model, training = training.sets, steps = 50)
  return(test)
}

library(parallel)
# Calculate the number of cores
no_cores <- detectCores()-1
# Initiate cluster
cl <- makeCluster(no_cores)
clusterEvalQ(cl, {source("spatiotempLOO.R")})
clusterExport(cl, "datspmod")
datList <- parLapply(cl, rsa, fitstloo, model = m5int)
stopCluster(cl)






library(sp)
library(gstat)
library(xts)
library(spacetime)

# get data into annoying spacetime format
dat<-data.frame(SiteID = datspmod$SiteID, Year = datspmod$Year, resids=residuals(m5int))

allcombo <- expand.grid(unique(datspmod$Year), unique(datspmod$SiteID))
names(allcombo) <- c("Year", "SiteID")
stdat <- merge(allcombo, dat, by = c("Year", "SiteID"), all.x = TRUE)

sites <- unique(datspmod[, c("SiteID", "lat", "lon")])
row.names(sites) <- sites$SiteID
sites <- sites[, -1]
sites <- SpatialPoints(sites)

dat$tsyear <- paste("01-01-", dat$Year, sep = "")
dat$tsyear <- mdy(dat$tsyear)
time <- sort(unique(dat$tsyear))

sd <- STFDF(sites, time, stdat)
stsdf <- as(sd, "STSDF") 

# space time variography
# basically shows that (for species I looked at) semivariance plateaus around .2 to .3

# bubble plot of residuals over space
spdf<-data.frame(SiteID = datspmod$SiteID, Year = datspmod$Year, resids=residuals(m5int),
                 lat = datspmod$lat, lon = datspmod$lon)
coordinates(spdf) <- c("lon", "lat")
bubble(spdf, "resids", col = c("blue", "orange"), main = "Residuals", xlab = "X-coordinates", 
    ylab = "Y-coordinates")

# pooled variogram (time selection with replacement)
rs = sample(dim(stsdf)[2], 100, replace = TRUE)
lst = lapply(rs, function(i) { x = stsdf[,i]; x$ti = i; rownames(x@coords) = NULL; x} )
 pts = do.call(rbind, lst)
 v = variogram(resids~ti, pts[!is.na(pts$resids),], dX=0, width = .08)
  vmod = fit.variogram(v, vgm("Sph"))
plot(v, vmod)

 # space time variogram
 vv = variogram(resids~1, stsdf, width=.05, tlags=0:5)
plot(vv)
plot(vv, map = FALSE)






library(geoR)
dists <- dist(datspmod[, c("lat", "lon")])
summary(dists)

breaks = seq(0, 2, l = 20)

vg <- variog(coords = datsp[, c("lat", "lon")], data = residuals(m5int), breaks = breaks)

library(gstat)
library(sp)

spatdat <- cbind(datspmod, z.value)

counts <- spatdat %>% 
  group_by(SiteID, Year) %>%
  summarise(Total = z.value)

count_matrix <- as.matrix(cast(counts, SiteID ~ Year, value = "Total"))
sites <- unique(spatdat[, c("SiteID", "lat", "lon")])
coordinates(sites)<-c('lon','lat')



var.mod<-variogram(resids~1,data = dat[dat$year == 2010,])
plot(var.mod)


library(gstat)
library(sp)
data(meuse)
coordinates(meuse)=~x+y
v1 = variogram(log(zinc)~1,meuse)
v2 = variogram(log(cadmium)~1,meuse)
m1 = fit.variogram(v1, vgm(1, "Sph", 800, 1))
m2 = fit.variogram(v2, vgm(1, "Sph", 800, 1))
plot(gamma~dist, v2, ylim = c(0, 1.05*max(v2$gamma)),col='red', ylab =
'semivariance', xlab = 'distance')
lines(variogramLine(m2, 1500), col='red')
points(gamma~dist, v1, col='blue')
lines(variogramLine(m1, 1500), col='blue')


m5intyr <- update(m5int, . ~ . + YearFact)
z.value <- residuals(m5int)
x.coord <- datspmod$lon
y.coord <- datspmod$lat
w <- datspmod$Year
library(ncf)
ncf.cor <- correlog(x = x.coord, y = y.coord, z = z.value, w = w,
                    increment=.1, resamp=500)
plot(ncf.cor)

#yearly residuals
library(reshape)
spatdat <- cbind(datspmod, z.value)

counts <- spatdat %>% 
  group_by(SiteID, Year) %>%
  summarise(Total = z.value)

count_matrix <- as.matrix(cast(counts, SiteID ~ Year, value = "Total"))
sites <- unique(spatdat[, c("SiteID", "lat", "lon")])

ncf.cor <- correlog(sites$lon, sites$lat, count_matrix,
                    increment=.5, resamp=500, latlon = TRUE, na.rm = TRUE)
plot(ncf.cor)



# try another
library(CommunityCorrelogram)
samData <- as.matrix(cast(counts, Year ~ SiteID, value = "Total"))
  
test <- commcorrelogram(sampleData = samData, sampleTime = c(1997:2014),
                        sampleLocation = cbind(sites[, c("lon", "lat")], z = 0),
                        LocationNames = as.character(sites[, "SiteID"]),
                        option = 3, lagSize=0.3,lagNumber=17,lagTol=0.15, numTests = 10)

spdata <- cbind(x.coord, y.coord, z.value)

vario <- variogram(z.value ~ 1, spdata, cutoff = 3)
plot(vario, pch = 16, cex = 1.5)
```



```{r stloo parallel}
# source('spatiotempLOO.R')

datmod$YearFact <- as.factor(datmod$Year)
sitemeans <- readRDS("data/sitemeans.rds")

datmod2 <- merge(datmod, sitemeans[, c("zmean", "SiteID"), with = FALSE], by = "SiteID")

site_geo <- fread("C:/Users/Tyson/Desktop/Box Sync/Ohio/GIS/OHsites_reconciled.csv", header = TRUE)
site_geo[, SiteID := formatC(as.numeric(Name), width = 3, format = "d", flag = "0")]

# jitter coordinates slightly
site_geo$lat <- site_geo$lat + rnorm(length(site_geo$lat), mean = 0, sd = 0.0001)
site_geo$lon <- site_geo$lon + rnorm(length(site_geo$lon), mean = 0, sd = 0.0001)

datmod2 <- merge(datmod2, site_geo[, c("SiteID", "lat", "lon"), with = FALSE], by = "SiteID")
datmod3 <- datmod2 %>%
  rowwise() %>%
  mutate(allmeantemp = mean(c(prevspr_meanTemp, prevsum_meanTemp, fall_meanTemp,
                              winter_meanTemp, spring_meanTemp, currsum_meanTemp)))

datmodcut <- datmod3 %>%
  group_by(sp) %>%
  dplyr::mutate(numobs = length(growth_ukbms_add1)) %>%
  dplyr::mutate(ddsite_ukbms_square = I(ddsite_ukbms^2)) %>%
  filter(numobs > 100)

datmodcut <- as.data.frame(datmodcut)

datmodcut <- datmodcut[, c("lat", "lon", "PC1", "PC2", "PC3", "SiteID", "Year", "YearFact", "sp",
                           "growth_ukbms_add1",
                           "ddsite_ukbms", "ddsite_ukbms_square",
                           "siteanom_currsum_meanTemp",
                           "siteanom_spring_meanTemp",
                           "siteanom_winter_meanTemp",
                           "siteanom_fall_meanTemp",
                           "siteanom_prevsum_meanTemp",
                           "siteanom_prevspr_meanTemp",
                           "zmean", "allmeantemp")]

spec2model <- unique(datmodcut$sp)
# rsa <- c(0, 10, 20)
models <- c("dens", "land", "clim", "land.add", "land.mean", "clim.add", "clim.add.dens",
            "clim.int", "d.c.l.add", "d.c.l.int", "full", "noseason")


# models to use in 6 scenarios
modlist <- list()
modlist[["dens"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                  ddsite_ukbms_square)

modlist[["land"]] <- as.formula(growth_ukbms_add1 ~ 
                                   PC1 + PC2 + PC3)
modlist[["clim"]] <- as.formula(growth_ukbms_add1 ~ 
                                 zmean * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp))

modlist[["land.add"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                 ddsite_ukbms_square +
                                   PC1 + PC2 + PC3)

modlist[["land.mean"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                 ddsite_ukbms_square +
                                   zmean *(PC1 + PC2 + PC3))

modlist[["clim.add"]] <- as.formula(growth_ukbms_add1 ~ zmean + siteanom_currsum_meanTemp +
                                                               siteanom_spring_meanTemp +
                                                               siteanom_winter_meanTemp +
                                                               siteanom_fall_meanTemp +
                                                               siteanom_prevsum_meanTemp +
                                                               siteanom_prevspr_meanTemp)

modlist[["clim.add.dens"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                           ddsite_ukbms_square +
                                           zmean + siteanom_currsum_meanTemp +
                                           siteanom_spring_meanTemp +
                                           siteanom_winter_meanTemp +
                                           siteanom_fall_meanTemp +
                                           siteanom_prevsum_meanTemp +
                                           siteanom_prevspr_meanTemp)

modlist[["clim.int"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                 ddsite_ukbms_square +
                                 zmean * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp))


modlist[["d.c.l.add"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                 ddsite_ukbms_square +
                                 zmean * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp) +
                                   PC1 + PC2 + PC3)

modlist[["d.c.l.mean"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                 ddsite_ukbms_square +
                                 zmean * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp +
                                   PC1 + PC2 + PC3))

modlist[["d.c.l.int"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                 ddsite_ukbms_square +
                                 zmean * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp) +
                                   PC1 * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp) +
                                   PC2 * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp) +
                                   PC3 * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp))

modlist[["full"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                 ddsite_ukbms_square +
                                 zmean * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp +
                                            PC1 + PC2 + PC3) +
                                   PC1 * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp) +
                                   PC2 * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp) +
                                   PC3 * (siteanom_currsum_meanTemp +
                                            siteanom_spring_meanTemp +
                                            siteanom_winter_meanTemp +
                                            siteanom_fall_meanTemp +
                                            siteanom_prevsum_meanTemp +
                                            siteanom_prevspr_meanTemp))

modlist[["noseason"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
                                 ddsite_ukbms_square +
                                   zmean * (PC1 + PC2 + PC3) +
                                   allmeantemp * (PC1 + PC2 + PC3 + zmean))


argsdf <- expand.grid(spec2model, models)

argslist <- as.list(1:nrow(argsdf))

# 
# getTraining <- function(spec){
#   datsp <- datmodcut %>% filter(sp == spec)
#   datsp <- as.data.frame(datsp)
#   training.sets <- splittingCV(data = datsp,
#                                lon.lab="lon",
#                                lat.lab="lat",
#                                yr.lab = "Year",
#                                time.split = 3)
#   return(training.sets)
# }



# trainList <- list()
# for(spec in spec2model){
#   trainList[[spec]] <- getTraining(spec)
# }
trainList <- readRDS("CVtrainingsets.rds")

# what am I asking computationally?
test <- lapply(trainList, length)
regs <- sum(unlist(test)) #50000! stepwise regressions
# most complicated regression has 33 variables to run through

# devtools::install_github("rstudio/profvis")
# library(profvis)


library(MASS)
library(nlme)

fitCV <- function(rownum){
  temp <- argsdf[rownum, ]
  spec <- temp[1, 1]
  index <- as.character(temp[1,2])
  modcall <<- modlist[[index]]
  
  training.set <- trainList[[spec]]
  
  datsp <<- datmodcut %>% filter(sp == spec) 
  datsp <- as.data.frame(datsp)
  
  mfull <- try(gls(modcall, 
               data = datsp, 
               correlation = corExp(form = ~ lat + lon | YearFact), 
               method = "ML", control = list(maxIter = 100, opt = "optim")))
  
  test <- modSelect(full.mod = mfull, data = datsp, training = training.set, steps = 100)
  test$fullmod <- mfull
  test$stepmod <- try(stepAIC(mfull, direction = "backward", test = "Chisq", 
                          trace = 0, steps = 100))
  bfit <- stCV.rmse(model = test$stepmod, training = training.set, data = datsp)
  test$stepRMSE <- bfit$rmse
  test$stepR2train <- bfit$meanR2train
  test$stepR2test <- bfit$meanR2test
  # add step without geo correlation
  # mnaive <- try(gls(modcall, 
  #              data = datsp, 
  #              method = "ML", control = list(maxIter = 100, opt = "optim")))
  # test$stepmodnaive <- try(stepAIC(mnaive, direction = "backward", test = "Chisq", 
  #                         trace = 0, steps = 100))
  # bfit <- stCV.rmse(model = test$stepmodnaive, training = training.set, data = datsp)
  # test$stepnaiveRMSE <- bfit$rmse
  # test$stepnaiveR2 <- bfit$meanR2
  
  test$species <- spec
  test$model <- index
  return(test)
}

library(parallel)
# Calculate the number of cores
no_cores <- detectCores()
# Initiate cluster
cl <- makeCluster(8)
# cl <- makeCluster(2)
clusterEvalQ(cl, {source("spatiotempLOO.R"); library(dplyr); library(MASS); library(nlme)})
clusterExport(cl, c("datmodcut", "argsdf", "trainList", "modlist"), envir = .GlobalEnv)

system.time({datList1 <- parLapply(cl, argslist[c(1:42)], fitCV)})
system.time({datList2 <- parLapply(cl, argslist[c(43:84)], fitCV)})
system.time({datList3 <- parLapply(cl, argslist[c(85:126)], fitCV)})
system.time({datList4 <- parLapply(cl, argslist[c(127:168)], fitCV)})
system.time({datList5 <- parLapply(cl, argslist[c(169:210)], fitCV)})
system.time({datList6 <- parLapply(cl, argslist[c(211:252)], fitCV)})
system.time({datList7 <- parLapply(cl, argslist[c(253:294)], fitCV)})
system.time({datList8 <- parLapply(cl, argslist[c(295:336)], fitCV)})
system.time({datList9 <- parLapply(cl, argslist[c(337:378)], fitCV)})
system.time({datList10 <- parLapply(cl, argslist[c(379:420)], fitCV)})
system.time({datList11 <- parLapply(cl, argslist[c(421:462)], fitCV)})
system.time({datList12 <- parLapply(cl, argslist[c(463:504)], fitCV)})

stopCluster(cl)

saveRDS(datList1, "modelresults8.rds")





# saveRDS(datList, "speciesclimatemodels.rds")
datList <- c(readRDS("modelresults1.rds"),
                     readRDS("modelresults2.rds"),
                     readRDS("modelresults3.rds"),
                     readRDS("modelresults4.rds"),
                     readRDS("modelresults5.rds"),
                     readRDS("modelresults6.rds"),
                    readRDS("modelresults7.rds"),
                    readRDS("modelresults8.rds"))

library(rms)
library(interplot)

# Summarise predictive ability of different models and 3 different approaches to GLS
# datList <- readRDS("speciesclimatemodels.rds")
results <- list()
test <- datList
  for (m in 1:length(datList)){
    species <- datList[[m]]$species
    model <- datList[[m]]$model
    
    nobs <- datList[[m]]$fullmod$dims$N
    fullnpar <- datList[[m]]$fullmod$dims$p 
    fullrange <- coef(datList[[m]]$fullmod$modelStruct$corStruct, unconstrained = FALSE)
    fullrmse <- datList[[m]]$fullrmse
    if(is.null(fullrmse)) fullrmse <- NA
    fullmeanR2 <- datList[[m]]$fullmeanR2
    if(is.null(fullmeanR2)) fullmeanR2 <- NA
    full.loglik <- as.numeric(logLik(datList[[m]]$fullmod))

    stepnpar <- datList[[m]]$stepmod$dims$p 
    steprange <- coef(datList[[m]]$stepmod$modelStruct$corStruct, unconstrained = FALSE)
    steprmse <- datList[[m]]$stepRMSE
    stepmeanR2 <- datList[[m]]$stepR2
    step.loglik <- as.numeric(logLik(datList[[m]]$stepmod))

    
    npar <- datList[[m]]$fit$dims$p 
    range <- coef(datList[[m]]$fit$modelStruct$corStruct, unconstrained = FALSE)
    rmse <- datList[[m]]$rmse
    meanR2 <- datList[[m]]$meanR2
    stcv.loglik <- as.numeric(logLik(datList[[m]]$fit))

    
    results[[m]] <- data.frame(species = species,
                       model = model, 
                       Nobs = nobs,
                       p_full = fullnpar,
                       range_full = fullrange,
                       rmse_full = fullrmse,
                       r2_full = fullmeanR2,
                       ll_full = full.loglik,
                       p_step = stepnpar,
                       range_step = steprange,
                       rmse_step = steprmse,
                       r2_step = stepmeanR2,
                       ll_step = step.loglik,
                       p_stcv = npar,
                       range_stcv = range,
                       rmse_stcv = rmse,
                       r2_stcv = meanR2,
                       ll_stcv = stcv.loglik
                       )
  }

resdf <- rbindlist(results)
bestmods <- resdf %>%
  filter(model %in% c("dens", "land.add", "clim.add", "clim.int", "d.c.l.add", "d.c.l.int")) %>%
  group_by(species) %>%
  mutate(rank_rmse = base::rank(rmse_stcv, ties.method = "first")) 
bestmods <- bestmods %>% filter(rank_rmse == 1) %>% dplyr::select(species, model, Nobs, rmse_stcv, r2_stcv, ll_stcv)
  






# momentarily lack of resolve leads me back to hierarchical mixed models.
# worried about interactions/community effects being uninterpretable without grouping

# takes more than 50 minutes to fit, so I stopped it 

weather <- lmer(growth_ukbms_add1 ~ ddsite_ukbms + ddsite_ukbms_square + zmean * 
    (siteanom_currsum_meanTemp + siteanom_spring_meanTemp + siteanom_winter_meanTemp + 
        siteanom_fall_meanTemp + siteanom_prevsum_meanTemp + 
        siteanom_prevspr_meanTemp) + PC1 + PC2 + PC3 + 
             (1 + ddsite_ukbms + ddsite_ukbms_square + zmean +
                 siteanom_currsum_meanTemp + siteanom_spring_meanTemp + siteanom_winter_meanTemp + 
        siteanom_fall_meanTemp + siteanom_prevsum_meanTemp + 
        siteanom_prevspr_meanTemp + PC1 + PC2 + PC3|sp) , data = datmodcut, control = lmerControl(optCtrl=list(maxfun=1e6)))



resdf %>% filter(model %in% c("dens", "clim.add", "clim.int"))%>% arrange(species, rmse_stcv) %>% data.frame()
```


Compare adequacy of simple models
dd vs clim vs lu vs combined

```{r LRT model}
test <- resdf %>%
  filter(model %in% c("dens", "clim", "land", "d.c.l.add"))

# go through datList
# get fullmod ll and stcv mod ll for models to compare

results <- list()
  for (m in 1:length(datList)){
    species <- datList[[m]]$species
    model <- datList[[m]]$model
    nobs <- datList[[m]]$fullmod$dims$N
    npar_full <- datList[[m]]$fullmod$dims$p
    npar_stcv <- datList[[m]]$fit$dims$p
    rmse_full <- datList[[m]]$fullrmse
    rmse_stcv <- datList[[m]]$rmse
    ll_full <- datList[[m]]$fullmod$logLik
    ll_stcv <- datList[[m]]$fit$logLik
    
    basics <- data.frame(species = species,
            model = model,
            nobs  = nobs,
            npar_full = npar_full,
            npar_stcv = npar_stcv,
            rmse_full = rmse_full,
            rmse_stcv = rmse_stcv,
            ll_full = ll_full,
            ll_stcv = ll_stcv)
    
    results[[m]] <- basics
                       
  }

resdf <- rbindlist(results)

# compare unnested models via adequacy
compmod <- c("dens", "land", "clim", "land.add", "land.mean", "clim.add", "clim.int", "d.c.l.add", "d.c.l.int")

  nagR2 <- function(nobs, ll.full, ll.null){
    r2 <- 1 - exp((-2/nobs) * (ll.full - ll.null))
    r2max <- 1 - exp((2/nobs) * ll.null)
    r2corr <- r2/r2max
    return(r2corr)
  }

results <- list()
  for (m in 1:length(spec2model)){
    
    spec <- spec2model[m]
    datsp <- datmodcut %>% filter(sp == spec) 
    datsp <- as.data.frame(datsp)
    
    nullmod <- try(gls(growth_ukbms_add1 ~ 1, 
                       data = datsp, 
                       correlation = corExp(form = ~ lat + lon | YearFact), 
                       method = "ML", control = list(maxIter = 100, opt = "optim")))
    ll.null <- as.numeric(logLik(nullmod))
    nobs <- nullmod$dims$N

    
    ll.comb_full <- resdf %>% filter(species == spec, model == "d.c.l.int") %>% dplyr::select(ll_full) %>% as.numeric()
    ll.comb_stcv <- resdf %>% filter(species == spec, model == "d.c.l.int") %>% dplyr::select(ll_stcv) %>%
      as.numeric()
    lr.comb_full <- -2*ll.null - ll.comb_full*-2
    lr.comb_stcv <- -2*ll.null - ll.comb_stcv*-2
    
    for (i in 1:length(compmod)){
      mod <- compmod[i]
      temp <- resdf %>% filter(species == spec, model == mod)
      lr_full <- -2*ll.null - temp$ll_full*-2
      lr_stcv <- -2*ll.null - temp$ll_stcv*-2
      adeq_full <- lr_full / lr.comb_full
      adeq_stcv <- lr_stcv / lr.comb_stcv
      modr2_full <- nagR2(nobs = nobs, ll.full = temp$ll_full, ll.null = ll.null)
      modr2_stcv <- nagR2(nobs = nobs, ll.full = temp$ll_stcv, ll.null = ll.null)

      
      out <- data.frame(species = spec,
                        model = mod,
                        lr_full = lr_full,
                        lr_stcv = lr_stcv,
                        adeq_full = adeq_full,
                        adeq_stcv = adeq_stcv,
                        lr.comb_full = lr.comb_full,
                        lr.comb_stcv = lr.comb_stcv,
                        nagr2_full = modr2_full,
                        nagr2_stcv = modr2_stcv)
      results[[length(results) + 1]] <- out
    }
    
  }

results2 <- rbindlist(results)

#mean adequacy across species
# compared dens vs land vs clim
# landuse not much use!
# when comparing model without density dependence
 results2 %>% group_by(model) %>% summarise(mean_adeq = mean(adeq_full))
 
modsumm <- resdf %>%
  group_by(model) %>%
  summarise(mean_npar_full = mean(npar_full),
            mean_npar_stcv = mean(npar_stcv),
            mean_rmse_full = mean(rmse_full),
            mean_rmse_stcv = mean(rmse_stcv))

# comparing dens vs land.add vs clim.int
out2 <-   results2 %>% 
  group_by(model) %>% 
  summarise(mean_adeq_full = mean(adeq_full),
            sd_adeq_full = sd(adeq_full),
            min_adeq_full = min(adeq_full),
            max_adeq_full = max(adeq_full),
            mean_adeq_stcv = mean(adeq_stcv),
            sd_adeq_stcv = sd(adeq_stcv),
            min_adeq_stcv = min(adeq_stcv),
            max_adeq_stcv = max(adeq_stcv),
            mean_nagr2_full = mean(nagr2_full),
            mean_nagr2_stcv = mean(nagr2_stcv))

out3 <- as.data.frame(merge(modsumm, out2, by = "model"))
out3[,-c(1:2)] <-round(out3[,-c(1:2)], 3) #the "-1" excludes column 1

prettyR::delim.table(out3, filename = "modelcomparison2.csv")


```


```{r traits}
OHtraits <- read.csv("data/OHtraits_R.csv") 
OHtraits$CommonName <- as.character(OHtraits$CommonName)
OHtraits$CommonName[2] <- "Azures"
OHtraits <- OHtraits[1:80, c("CommonName", "MinBrood", "MaxBroodNumb", 
                             "ResStatus", "WinterStage", "GenvsSpec")]
OHtraits <- OHtraits %>% filter(CommonName %in% spec2model)

# SpeciesList <- readRDS("SpeciesList.rds")
dispers <- read.csv("data/CanadaDispersalIndex.csv")
names(dispers)[4] <- "CommonName"
dispers$CommonName <- as.character(dispers$CommonName)


traits <- merge(OHtraits, dispers, by = "CommonName", all.x = TRUE)

missing <- traits$CommonName[which(is.na(traits$Mobility..mean.))]

#quick fill in, will do coded merge later 
#lots of spelling differences between two datasets

miss <- data.frame(CommonName = missing, Mobility..mean. = NA)
miss$Mobility..mean. <- c(5.5, 5.24, 6, 4.33, 5.37, 4.3, 5.12, 6.97, 7)

traits$Mobility..mean.[which(is.na(traits$Mobility..mean.))] <- miss$Mobility..mean.

traits <- traits[, c("CommonName", "MinBrood", "ResStatus", "WinterStage", "Mobility..mean.")]
names(traits)[5] <- "Dispersal"





```




# what R2 metric to use for predictive fit?
# I think what I did first was based on lm sum of squares, not valid in gls framework.

#Nagelkerke used in Harrell's book and package



Use this chunk to get marginal R2 for nested models with increasing complexity.
1. Compare dens -> land.add -> d.c.l.add
2. Compare dens -> clim.int -> d.c.l.add
3. Compare dens -> clim.int -> d.c.l.add -> d.c.l.int

```{r plot results variable subset predictive importance}
compmod <- models[c(1, 7, 9)]

  nagR2 <- function(nobs, ll.full, ll.null){
    r2 <- 1 - exp((-2/nobs) * (ll.full - ll.null))
    r2max <- 1 - exp((2/nobs) * ll.null)
    r2corr <- r2/r2max
    return(r2corr)
  }

# get resdf above before this loop
  results <- list()
  for (m in 1:length(spec2model)){
    
    spec <- spec2model[m]
    datsp <- datmodcut %>% filter(sp == spec) 
    datsp <- as.data.frame(datsp)
    
    nullmod <- try(gls(growth_ukbms_add1 ~ 1, 
                       data = datsp, 
                       correlation = corExp(form = ~ lat + lon | YearFact), 
                       method = "ML", control = list(maxIter = 100, opt = "optim")))
    ll.null <- as.numeric(logLik(nullmod))
    
    for (i in 1:length(compmod)){
      mod <- compmod[i]
      temp <- resdf %>% filter(species == spec, model == mod)
      prevmod <- compmod[i-1]
      prevtemp <- resdf %>% filter(species == spec, model == prevmod)
      
      if (mod == "dens"){
        modr2_full <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_full, ll.null = ll.null)
        partr2_full <- NA
        modr2_step <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_step, ll.null = ll.null)
        partr2_step <- NA
        modr2_stcv <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_stcv, ll.null = ll.null)
        partr2_stcv <- NA
        
      }else{
        
        modr2_full <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_full, ll.null = ll.null)
        partr2_full <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_full, ll.null = prevtemp$ll_full)
        modr2_step <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_step, ll.null = ll.null)
        partr2_step <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_step, ll.null = prevtemp$ll_step)
        modr2_stcv <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_stcv, ll.null = ll.null)
        partr2_stcv <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_stcv, ll.null = prevtemp$ll_stcv)
      }
      
      out <- data.frame(species = spec,
                        model = mod,
                        modr2_full = modr2_full,
                        partr2_full = partr2_full,
                        modr2_step = modr2_step,
                        partr2_step = partr2_step,
                        modr2_stcv = modr2_stcv,
                        partr2_stcv = partr2_stcv)
      results[[length(results) + 1]] <- out
    }
    
  }

resdf2 <- rbindlist(results)
landuse_margr2 <- resdf2
climate_margr2 <- resdf2
interaction_margr2 <- resdf2

library(ggrepel)
# plot of landuse/climate additive variable importance
pltdat  <- gather(landuse_margr2, metric, measurement, modr2_full:partr2_stcv)
densonly <- pltdat %>% filter(model == "dens") %>% filter(metric == "modr2_stcv")
landmarg <- pltdat %>% filter(model == "land.add") %>% filter(metric == "partr2_stcv")
climmarg <- pltdat %>% filter(model == "d.c.l.add") %>% filter(metric == "partr2_stcv")
pltdat <- data.frame(species = unique(pltdat$species), density = densonly$measurement, landuse = landmarg$measurement, climate = climmarg$measurement)
pltdat$landuse_scaled <- exp(pltdat$landuse)
pltdat[27,3] <- 0 #issues with Pearl Crescent landuse r2 being negative
a <- ggplot(data = pltdat, aes(x = landuse, y = climate)) + theme_bw() + 
    geom_text_repel(aes(label = species), 
       box.padding = unit(0.45, "lines")) +
    geom_point(colour = "black", size = 2) + scale_x_sqrt() + 
  labs(x = "Marginal R2 when adding landuse variables", y = "Marginal R2 when adding climate variables ",
              title = "Improved model fit of annual growth rates\n when including climate or landuse variables") +
              # subtitle = "Darker line shows average phenology for species or site.") +
            theme(legend.position="none",
                  strip.text.x = element_text(size=12),
                  axis.title.x = element_text(size=16),
                  axis.text.x  = element_text(size=12),
                  axis.title.y = element_text(size=16),
                  axis.text.y  = element_text(size=12),
                  plot.title = element_text(size = 20, face="bold"))

# plot of landuse/climate interaction variable importance
pltdat  <- gather(interaction_margr2, metric, measurement, modr2_full:partr2_stcv)
densonly <- pltdat %>% filter(model == "dens") %>% filter(metric == "modr2_full")
intmarg <- pltdat %>% filter(model == "d.c.l.int") %>% filter(metric == "partr2_full")
addmarg <- pltdat %>% filter(model == "clim.int") %>% filter(metric == "partr2_full")
pltdat <- data.frame(species = unique(pltdat$species), density = densonly$measurement, additive = addmarg$measurement, interaction = intmarg$measurement)

pltdat$interaction[which(pltdat$interaction < 0)] <- 0

a <- ggplot(data = pltdat, aes(x = interaction, y = additive)) + theme_bw() + 
    geom_text_repel(aes(label = species), 
       box.padding = unit(0.45, "lines")) +
    geom_point(colour = "black", size = 2) + scale_x_sqrt() + expand_limits(x = 0, y = 0) +
  labs(x = "Marginal R2 when adding climate x landuse interaction", y = "Marginal R2 of only climate variables ",
              title = "Improved model fit of annual growth rates\n when including climate by landuse interaction") +
              # subtitle = "Darker line shows average phenology for species or site.") +
            theme(legend.position="none",
                  strip.text.x = element_text(size=12),
                  axis.title.x = element_text(size=16),
                  axis.text.x  = element_text(size=12),
                  axis.title.y = element_text(size=16),
                  axis.text.y  = element_text(size=12),
                  plot.title = element_text(size = 20, face="bold"))




names(pltdat)[1] <- "CommonName"
trdat <- merge(traits, pltdat)
trdat$ResStatus <- mapvalues(trdat$ResStatus, from = "naturalized", to = "resident")
trdat[14,4] <- "larva"
trdat$MinBrood <- as.character(trdat$MinBrood)

library(GGally)
# residency vs climate/landuse/density
p <- ggpairs(dat = trdat, columns = c(3, 5:8),
             lower = list(combo = "blank", discrete = "blank"),
             upper = list(combo = "box"),
             diag = list(discrete = "blankDiag")) + theme_bw()

trdat_res <- trdat %>% filter(ResStatus == "resident")
p <- ggpairs(dat = trdat_res, columns = c(2, 4, 5:8),
             lower = list(combo = "blank", discrete = "blank"),
             upper = list(combo = "box"),
             diag = list(discrete = "blankDiag")) + theme_bw()


predresults <- merge(resdf, resdf2, by = c("species", "model"), all.x = FALSE, all.y = TRUE)


saveRDS(predresults, "predictionresults.rds")

  
```





```{r plot results prediction of different approaches}

# datList of details and resdf of extracted fit data
readRDS("predictionresults.rds")
# how do the 3 modeling approaches compare for a highly-parameterized model
# in general, step and stcv are exactly the same in predictive ability and 
# number of selected variables, full model performs worse

tabdat <- resdf %>%
  group_by(model) %>%
  summarise(npar_full = mean(p_full),
            rmse_full = mean(rmse_full),
            R2_full = mean(modr2_full),
            npar_step = mean(p_step),
            rmse_step = mean(rmse_step),
            R2_step = mean(modr2_step),
            npar_stcv = mean(p_stcv),
            rmse_stcv = mean(rmse_stcv),
            R2_stcv = mean(modr2_stcv),
            sd_rmse_full = sd(rmse_full),
            sd_R2_full = sd(modr2_full),
            sd_npar_step = sd(p_step),
            sd_rmse_step = sd(rmse_step),
            sd_R2_step = sd(modr2_step),
            sd_npar_stcv = sd(p_stcv),
            sd_rmse_stcv = sd(rmse_stcv),
            sd_R2_stcv = sd(modr2_stcv))
  
sumtab <- tabdat[, 1:10, with = FALSE] %>% data.frame()
sumtab[ , order(names(sumtab))]


# move from wide to long data
library(tidyr)
library(ggplot2)

# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
data_long <- gather(predresults, metric, measurement, p_full:partr2_stcv)

library(stringr)
data_long$var <- str_split_fixed(data_long$metric, "_", 2)[,1]
data_long$approach <- str_split_fixed(data_long$metric, "_", 2)[,2]

npardat <- data_long %>%
  filter(var == "p", model == "d.c.l.int")
npars <- ggplot(npardat, aes(x = approach, y = measurement)) + geom_boxplot() +
  ylab("Number of parameters") +
  ggtitle(label = "Reducing variables through selection")

rmsedat <- data_long %>%
  filter(var == "rmse", model == "d.c.l.int")
rmseplot <- ggplot(rmsedat, aes(x = approach, y = measurement)) + 
  geom_boxplot() +
  ylab("Root mean squared error") +
  ggtitle(label = "RMSE for different modeling approaches")

r2dat <- data_long %>%
  filter(var == "modr2", model == "d.c.l.int")
r2plot <- ggplot(r2dat, aes(x = approach, y = measurement)) + 
  geom_boxplot() +
  ylab("R-squared") +
  ggtitle(label = "r2 for different modeling approaches")


# compare models including density and climate variables for each species
# metric is predictive ability

tab_dens <- predresults %>%
  filter(model == "dens") %>%
  dplyr::select(species, Nobs, model, p_stcv, rmse_stcv, modr2_stcv)
tab_dc <- predresults %>%
  filter(model == "d.c") %>%
  dplyr::select(species, model, p_stcv, rmse_stcv, modr2_stcv, partr2_stcv)
tab_dcladd <- predresults %>%
  filter(model == "d.c.l.add") %>%
  dplyr::select(species, model, p_stcv, rmse_stcv, modr2_stcv, partr2_stcv)
tab_dclint <- predresults %>%
  filter(model == "d.c.l.int") %>%
  dplyr::select(species, model, p_stcv, rmse_stcv, modr2_stcv, partr2_stcv)

tabspec <- cbind(tab_dens, tab_dc[,-1, with = FALSE], tab_dcladd[,-1, with = FALSE], tab_dclint[, -1, with = FALSE])




```


```{r plot results important variables}


  nagR2 <- function(nobs, ll.full, ll.null){
    r2 <- 1 - exp((-2/nobs) * (ll.full - ll.null))
    r2max <- 1 - exp((2/nobs) * ll.null)
    r2corr <- r2/r2max
    return(r2corr)
  }

# get resdf above before this loop
results <- list()
for (m in 1:length(spec2model)){
  
  spec <- spec2model[m]
  datsp <- datmodcut %>% filter(sp == spec) 
  datsp <- as.data.frame(datsp)
  
  nullmod <- try(gls(growth_ukbms_add1 ~ 1, 
                     data = datsp, 
                     correlation = corExp(form = ~ lat + lon | YearFact), 
                     method = "ML", control = list(maxIter = 100, opt = "optim")))
  ll.null <- as.numeric(logLik(nullmod))
  
  temp <- bestmods %>% filter(species == spec)
  
  nagR2spec <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_stcv, ll.null = ll.null)
  
  out <- data.frame(species = spec,
                    model = temp$model,
                    nagR2 = nagR2spec)
  results[[length(results) + 1]] <- out
  
}

nagR2bestmods <- rbindlist(results)
bestmods2 <- merge(bestmods, nagR2bestmods, by = c("species", "model"))

#extract coefficients from stcv models for all species

results <- list()
  for (m in 1:length(datList)){
    species <- datList[[m]]$species
    model <- datList[[m]]$model
    nobs <- datList[[m]]$fullmod$dims$N
    npar <- datList[[m]]$fit$dims$p 
    rmse <- datList[[m]]$rmse
    meanR2 <- datList[[m]]$meanR2
    
    basics <- data.frame(species = species,
                       model = model, 
                       Nobs = nobs,
                       p_stcv = npar,
                       rmse_stcv = rmse,
                       r2_stcv = meanR2,
                       variable = NA,
                       coef_effect = NA)
    
    outdf <- data.frame()
    for (i in 1:length(datList[[m]]$fit$coefficients)){
      tempdf <- basics
      tempdf$variable <- names(datList[[m]]$fit$coefficients)[i]
      tempdf$coef_effect <- datList[[m]]$fit$coefficients[i]
      
      outdf <- rbind(outdf, tempdf)
    }
    results[[m]] <- outdf
                       
  }

resdf <- rbindlist(results)


test <- merge(bestmods2, resdf, by = c("species", "model", "Nobs", "rmse_stcv", "r2_stcv"), all.x = TRUE, all.y = FALSE)

# test <- resdf %>% filter(model == "d.c.l.add")
# try out table of speces x parameters for d.c model

tabdat <- test
tabdat$coef_effect <- round(tabdat$coef_effect, 2)
tabdat$rmse_stcv <- round(tabdat$rmse_stcv, 2)
tabdat$r2_stcv <- round(tabdat$r2_stcv, 2)

# messy, so many parameters!
tabdat <- as.data.frame(spread(tabdat, variable, coef_effect, fill = "."))

library(prettyR)
delim.table(tabdat, filename = "test.table.csv", delim = ",")
delim.table(tabdat, filename = "test.table2.csv", delim = ",")

# number of species models with each variable
nvar <- tabdat %>% group_by(variable) %>%
  summarise(nspecies = n())

# make new data.frame of label data
vars <- factor(c("(Intercept)", "ddsite_ukbms","ddsite_ukbms_square",            
 "PC1","PC2","PC3",                            
"siteanom_prevspr_meanTemp", "siteanom_prevsum_meanTemp", "siteanom_fall_meanTemp",             "siteanom_winter_meanTemp","siteanom_spring_meanTemp","siteanom_currsum_meanTemp",                
"zmean","zmean:siteanom_prevspr_meanTemp", "zmean:siteanom_prevsum_meanTemp", "zmean:siteanom_fall_meanTemp", "zmean:siteanom_winter_meanTemp" ,   
 "zmean:siteanom_spring_meanTemp","zmean:siteanom_currsum_meanTemp"  
), levels = c("(Intercept)", "ddsite_ukbms","ddsite_ukbms_square",            
 "PC1","PC2","PC3",                            
"siteanom_prevspr_meanTemp", "siteanom_prevsum_meanTemp", "siteanom_fall_meanTemp",             "siteanom_winter_meanTemp","siteanom_spring_meanTemp","siteanom_currsum_meanTemp",                
"zmean","zmean:siteanom_prevspr_meanTemp", "zmean:siteanom_prevsum_meanTemp", "zmean:siteanom_fall_meanTemp", "zmean:siteanom_winter_meanTemp" ,   
 "zmean:siteanom_spring_meanTemp","zmean:siteanom_currsum_meanTemp"  
))
categor <- c(rep("Density-dependence", 3),
              rep("Land-use PCs", 3),
              rep("Seasonal anomalies", 6),
              rep("Site temperature interaction", 7))
varname <- factor(c("Intercept", "Linear DD", "Quad DD", "PC1: Agri\n to urban", 
             "PC2: Forest\n to urban", "PC3: Forest/urban\n to grass/wetlands",
             "Previous\n spring", "Previous\n summer", "Previous\n fall", "Winter", "Spring", "Summer",
             "Mean\n site\ntemperature", "Mean:\nPrevious\n spring", "Mean:\nPrevious\n summer",
             "Mean:\nPrevious\n fall", "Mean:\nWinter", "Mean:\nSpring", "Mean:\nSummer"),
             levels = c("Intercept", "Linear DD", "Quad DD", "PC1: Agri\n to urban", 
             "PC2: Forest\n to urban", "PC3: Forest/urban\n to grass/wetlands",
             "Previous\n spring", "Previous\n summer", "Previous\n fall", "Winter", "Spring", "Summer",
             "Mean\n site\ntemperature", "Mean:\nPrevious\n spring", "Mean:\nPrevious\n summer",
             "Mean:\nPrevious\n fall", "Mean:\nWinter", "Mean:\nSpring", "Mean:\nSummer"))
varDF <- data.frame(variable = vars, categor = categor, varname = varname)

boxdat <- merge(varDF, tabdat, by = "variable")


b <- ggplot(data = boxdat, aes(x = variable, y = coef_effect)) + geom_boxplot() +
  geom_hline(yintercept = 0, linetype = "dashed") + theme_bw() +
   labs(x = "Variable selected in species model", y = "Size of effect when variable included in models",
              title = "Variable effects when selected in species models") +
              # subtitle = "Darker line shows average phenology for species or site.") +
            theme(legend.position="none",
                  strip.text.x = element_text(size=12),
                  axis.title.x = element_text(size=16),
                  axis.text.x  = element_text(size=12, angle = 90),
                  axis.title.y = element_text(size=16),
                  axis.text.y  = element_text(size=12),
                  plot.title = element_text(size = 20, face="bold")) +
  geom_text(data = nvar, aes(x = variable, y = 1, label = nspecies), size = 2) +
  scale_x_discrete(breaks = levels(boxdat$variable),
                      labels = varDF$varname) +

  # arrange grid of boxplots by variable type
library(gridExtra)
b1dat <- subset(boxdat, categor == "Density-dependence")
nvar <- b1dat %>% group_by(variable) %>%
  summarise(nspecies = n())
b1 <- ggplot(data = b1dat, 
             aes(x = variable, y = coef_effect)) + geom_boxplot() +
  geom_hline(yintercept = 0, linetype = "dashed") + theme_bw() +
   labs(x = "Density-dependence", y = "Effect size") +
            theme(legend.position="none",
                  strip.text.x = element_text(size=12),
                  axis.title.x = element_text(size=16),
                  axis.text.x  = element_text(size=12),
                  axis.title.y = element_text(size=16),
                  axis.text.y  = element_text(size=12), 
                  plot.margin = unit(c(.5, .5, .5, .5), "cm")) +
  geom_text(data = nvar, aes(x = variable, y = 1, label = nspecies), size = 5) +
  scale_x_discrete(breaks = unique(b1dat$variable),
                      labels = unique(b1dat$varname))

b2dat <- subset(boxdat, categor == "Land-use PCs")
nvar <- b2dat %>% group_by(variable) %>%
  summarise(nspecies = n())
b2 <- ggplot(data = b2dat, 
             aes(x = variable, y = coef_effect)) + geom_boxplot() +
  geom_hline(yintercept = 0, linetype = "dashed") + theme_bw() +
   labs(x = "Land-use PCs", y = "Effect size") +
            theme(legend.position="none",
                  strip.text.x = element_text(size=12),
                  axis.title.x = element_text(size=16),
                  axis.text.x  = element_text(size=12),
                  axis.title.y = element_text(size=16),
                  axis.text.y  = element_text(size=12),
                  plot.margin = unit(c(.5, .5, .5, .5), "cm")) +
  geom_text(data = nvar, aes(x = variable, y = 1, label = nspecies), size = 5) +
  scale_x_discrete(breaks = unique(b2dat$variable),
                      labels = unique(b2dat$varname))

b3dat <- subset(boxdat, categor == "Seasonal anomalies")
nvar <- b3dat %>% group_by(variable) %>%
  summarise(nspecies = n())
b3 <- ggplot(data = b3dat, 
             aes(x = variable, y = coef_effect)) + geom_boxplot() +
  geom_hline(yintercept = 0, linetype = "dashed") + theme_bw() +
   labs(x = "Seasonal anomalies", y = "Effect size") +
            theme(legend.position="none",
                  strip.text.x = element_text(size=12),
                  axis.title.x = element_text(size=16),
                  axis.text.x  = element_text(size=12),
                  axis.title.y = element_text(size=16),
                  axis.text.y  = element_text(size=12),
                  plot.margin = unit(c(.5, .5, .5, .5), "cm")) +
  geom_text(data = nvar, aes(x = variable, y = 1, label = nspecies), size = 5) +
  scale_x_discrete(breaks = unique(b3dat$variable),
                      labels = unique(b3dat$varname))

b4dat <- subset(boxdat, categor == "Site temperature interaction")
nvar <- b4dat %>% group_by(variable) %>%
  summarise(nspecies = n())
b4 <- ggplot(data = b4dat, 
             aes(x = variable, y = coef_effect)) + geom_boxplot() +
  geom_hline(yintercept = 0, linetype = "dashed") + theme_bw() +
   labs(x = "Site temperature interaction", y = "Effect size") +
            theme(legend.position="none",
                  strip.text.x = element_text(size=12),
                  axis.title.x = element_text(size=16),
                  axis.text.x  = element_text(size=12),
                  axis.title.y = element_text(size=16),
                  axis.text.y  = element_text(size=12),
                  plot.margin = unit(c(.5, .5, .5, .5), "cm")) +
  geom_text(data = nvar, aes(x = variable, y = 1, label = nspecies), size = 5) +
  scale_x_discrete(breaks = unique(b4dat$variable),
                      labels = unique(b4dat$varname))
grid.arrange(b1, b2, b3, b4)


# plots of traits by variable effects
names(tabdat)[1] <- "CommonName"
trvars <- merge(tabdat, traits, by = "CommonName")
fil <- unique(trvars$variable)[4:8]

mvdat <- trvars %>% filter(variable %in% fil)
mvdat$MinBrood <- as.factor(as.character(mvdat$MinBrood))
mvdat$VAR <- as.factor(mvdat$variable)

mv <- ggplot(mvdat, aes(x = MinBrood, y = coef_effect)) +
  geom_boxplot() + facet_wrap( ~ VAR)


```


```{r interaction}
######
# make graphs of interactions
# some problems with singular fits in gls




  nagR2 <- function(nobs, ll.full, ll.null){
    r2 <- 1 - exp((-2/nobs) * (ll.full - ll.null))
    r2max <- 1 - exp((2/nobs) * ll.null)
    r2corr <- r2/r2max
    return(r2corr)
  }

# get resdf above before this loop
results <- list()
for (m in 1:length(spec2model)){
  
  spec <- spec2model[m]
  datsp <- datmodcut %>% filter(sp == spec) 
  datsp <- as.data.frame(datsp)
  
  nullmod <- try(gls(growth_ukbms_add1 ~ 1, 
                     data = datsp, 
                     correlation = corExp(form = ~ lat + lon | YearFact), 
                     method = "ML", control = list(maxIter = 100, opt = "optim")))
  ll.null <- as.numeric(logLik(nullmod))
  
  temp <- bestmods %>% filter(species == spec)
  
  nagR2spec <- nagR2(nobs = temp$Nobs, ll.full = temp$ll_stcv, ll.null = ll.null)
  
  out <- data.frame(species = spec,
                    model = temp$model,
                    nagR2 = nagR2spec)
  results[[length(results) + 1]] <- out
  
}

nagR2bestmods <- rbindlist(results)
bestmods2 <- merge(bestmods, nagR2bestmods, by = c("species", "model"))

#extract coefficients from stcv models for all species

results <- list()
  for (m in 1:length(datList)){
    species <- datList[[m]]$species
    model <- datList[[m]]$model
    nobs <- datList[[m]]$fullmod$dims$N
    npar <- datList[[m]]$fit$dims$p 
    rmse <- datList[[m]]$rmse
    meanR2 <- datList[[m]]$meanR2
    
    basics <- data.frame(species = species,
                       model = model, 
                       Nobs = nobs,
                       p_stcv = npar,
                       rmse_stcv = rmse,
                       r2_stcv = meanR2,
                       variable = NA,
                       coef_effect = NA)
    
    outdf <- data.frame()
    for (i in 1:length(datList[[m]]$fit$coefficients)){
      tempdf <- basics
      tempdf$variable <- names(datList[[m]]$fit$coefficients)[i]
      tempdf$coef_effect <- datList[[m]]$fit$coefficients[i]
      
      outdf <- rbind(outdf, tempdf)
    }
    results[[m]] <- outdf
                       
  }

resdf <- rbindlist(results)


test <- merge(bestmods2, resdf, by = c("species", "model", "Nobs", "rmse_stcv", "r2_stcv"), all.x = TRUE, all.y = FALSE)
tabdat <- test



# tabdat has all included coefficients in each species best models
# merge with species traits and do permutation tests for non-random associations
library(coin)
tabdat <- as.data.frame(spread(tabdat, variable, coef_effect, fill = 0))

# use just additive coefficients, represent interactions at the mean condition
adddat <- tabdat[, -grep(pattern = ":", names(tabdat))]
# get traits dataset processing from above
names(traits)[1] <- "species"

sptrait <- merge(adddat, traits, by = "species", all.x = TRUE, all.y = FALSE)
sptrait <- droplevels.data.frame(sptrait)
sptrait$MinBrood <- factor(as.character(sptrait$MinBrood), levels = c("1", "2", "3"))

traits <- c("MinBrood", "ResStatus", "WinterStage", "Dispersal")
yvars <- names(sptrait)[12:21]
for (y in yvars){
  for (t in traits){
    temp <- sptrait[, c(y, t)]
    permform <- as.formula(paste(y,t, sep = " ~ "))
    (indtest <- independence_test(permform, data = temp,
                                  ytrafo = function(data)
                                    rank_trafo(data, ties.method = "random"),
                                  distribution = approximate(B = 9999)))
    plot(temp[,2], temp[,1],
     main = paste(y, "~", t, "Pvalue =", round(pvalue(indtest), 3), sep = " "))
  }
}
rtfgb b 

# number of species models with each variable
nvar <- tabdat %>% group_by(variable) %>%
  summarise(nspecies = n())

# get best model from each species from datList
# predict with new data for plotting
# what is datList index for each species/model?
indexdf <- list()
for (i in 1:length(datList)){
  indexdf[[i]] <- data.frame(index = i, species = datList[[i]]$species, model = datList[[i]]$model)
}
res_index <- rbindlist(indexdf)


################################################################
# start with easy plot
# density dependence for all species
ddlist <- list()
for (i in 1:length(spec2model)){
  spec <- spec2model[i]
  species_mod <- datList[[res_index$index[which(res_index$species == spec &
                                                  res_index$model == test$model[which(test$species == spec)][1])]]]$fit
  species_data <- datmodcut %>% filter(sp == spec)
  coefs <- coef(species_mod)
  add.coef <- names(coefs)[grep(pattern = "ddsite|Intercept", names(coefs))]
  
  if(length(add.coef) == 2){
    beta0 <- species_mod$coefficients[[add.coef[1]]]
    beta1 <- species_mod$coefficients[[add.coef[2]]]
    # Set range of the moderator variable
    min_val = min(species_data$ddsite_ukbms)
    max_val = max(species_data$ddsite_ukbms)
    
    num_points = 50
    increment = (max_val - min_val)/(num_points - 1)
    
    x <- seq(from=min_val, to=max_val, by=increment)
    y = beta0 + beta1 * x
    densdf <- data.frame(ddsite = x, growthrate = y)
  }
  
  if(length(add.coef) == 3){
    beta0 <- species_mod$coefficients[[add.coef[1]]]
    beta1 <- species_mod$coefficients[[add.coef[2]]]
    beta2 <- species_mod$coefficients[[add.coef[3]]]
    # Set range of the moderator variable
    min_val = min(species_data$ddsite_ukbms)
    max_val = max(species_data$ddsite_ukbms)
    
    num_points = 50
    increment = (max_val - min_val)/(num_points - 1)
    
    x <- seq(from=min_val, to=max_val, by=increment)
    y = beta0 + beta1 * x + beta2 * (x^2)
    densdf <- data.frame(ddsite = x, growthrate = y)
  }
  
  out <- densdf
  out$species <- spec
  ddlist[[i]] <- out
}

densdf <- data.table::rbindlist(ddlist)

dd <- ggplot(data = densdf, aes(y = growthrate, x = ddsite, group = species)) + 
  geom_line(size = 1, alpha = .6)
dd + geom_hline(yintercept = 0, linetype = "dashed") + theme_bw() +
   labs(x = "Previous year's population size (scaled by site)", 
        y = "Predicted log(growth rate)",
        title = "Effect of population density on population growth for all species") +
            theme(legend.position="none",
                  strip.text.x = element_text(size=12),
                  axis.title.x = element_text(size=16),
                  axis.text.x  = element_text(size=12),
                  axis.title.y = element_text(size=16),
                  axis.text.y  = element_text(size=12))

#############################################
vars <- c("siteanom_prevspr_meanTemp", "siteanom_prevsum_meanTemp", "siteanom_fall_meanTemp",             "siteanom_winter_meanTemp","siteanom_spring_meanTemp","siteanom_currsum_meanTemp")
varlist <- as.list(vars)
out <- data.frame()
for (k in vars){
  varname <- k
  for (i in 1:length(spec2model)){
    spec <- spec2model[i]
    species_mod <- datList[[res_index$index[which(res_index$species == spec &
                                                    res_index$model == test$model[which(test$species == spec)][1])]]]$fit
    species_data <- datmodcut %>% filter(sp == spec)
    coefs <- coef(species_mod)
    varcoef <- names(coefs)[grep(pattern = varname, names(coefs))]
    # add.coef <- varcoef[-grep(pattern = ":", varcoef)]
    int.coef <- varcoef[grep(pattern = ":", varcoef)]
    covMat = vcov(species_mod)
    
    
    
    if(length(varcoef) == 0) next
    if(length(int.coef) == 0) next
    
    for (j in 1:length(int.coef)){
      interaction <- int.coef[j]
      intsplit <- stringr::str_split_fixed(interaction, ":", 2)
      effect <- intsplit[which(intsplit == varname)]
      moderator <- intsplit[-which(intsplit == varname)]
      
      # Get coefficients of variables
      beta_1 = species_mod$coefficients[[effect]]
      beta_3 = species_mod$coefficients[[interaction]]
      
      # Set range of the moderator variable
      min_val = min(species_data[[moderator]])
      max_val = max(species_data[[moderator]])
      
      # Determine intervals between values of the moderator
      num_points = 50
      increment = (max_val - min_val)/(num_points - 1)
      
      # Create list of moderator values at which marginal effect is evaluated
      x_2 <- seq(from=min_val, to=max_val, by=increment)
      
      # Compute marginal effects
      delta_1 = beta_1 + beta_3*x_2
      
      # Compute variances
      var_1 = covMat[effect,effect] + (x_2^2)*covMat[interaction, interaction] + 2*x_2*covMat[effect, interaction]
      
      # Standard errors
      se_1 = sqrt(var_1)
      
      # Upper and lower confidence bounds
      z_score = qnorm(1 - ((1 - conf)/2))
      upper_bound = delta_1 + z_score*se_1
      lower_bound = delta_1 - z_score*se_1
      
      temp <- data.frame(Species = spec, Variable = effect, Moderator = moderator,
                        Xcov = x_2, Ydelta = delta_1, upCI = upper_bound, lowCI = lower_bound)
      out <- rbind(out, temp)
    }
  }
}


for (k in vars){
  
  intdf <- out %>% filter(Variable == k)
  intdf$Moderator <- factor(intdf$Moderator, levels = c("zmean", "PC1", "PC2", "PC3"))
  
  ii <- ggplot(data = intdf, aes(y = Ydelta, x = Xcov, group = Species)) +
    geom_line(size = 1, alpha = .6) +
    facet_wrap(~ Moderator) + 
    geom_hline(yintercept = 0, linetype = "dashed") + theme_bw() +
   labs(x = "Value of moderator covariate", 
        y = "Estimated marginal coefficient",
        title = paste("Interactions:\n Effect of", k, "changes with mean site temperature\n and land-use PC", sep = " ")) +
            theme(legend.position="none",
                  strip.text.x = element_text(size=12),
                  axis.title.x = element_text(size=16),
                  axis.text.x  = element_text(size=12),
                  axis.title.y = element_text(size=16),
                  axis.text.y  = element_text(size=12))
  print(ii)
}




# tougher than I thought!!


# try just d.c.l.add model for now
# trouble visualization landuse interactions
# datlist 211:252

library(effects)

test <- datList[[241]]
datsp <- datmodcut %>% filter(sp == test$species) 
  datsp <- as.data.frame(datsp) %>%
  mutate(zmean = as.numeric(zmean),
         ddsite_ukbms = as.numeric(ddsite_ukbms),
         ddsite_ukbms_square = as.numeric(ddsite_ukbms_square))
testmod <- gls(model = test$fit$call$model, 
               data = datsp, correlation =  corExp(form = ~lat + lon | YearFact),
              method = "ML", control = list(maxIter = 100, opt = "optim", singular.ok = TRUE))

effs <- allEffects(testmod)
plot(effs, type = "link")

eff <- effect("zmean:siteanom_prevspr_meanTemp", testmod)
plot(eff, multiline = TRUE,
     xlevels=list(zmean = seq(-2, 2, 2), siteanom_prevspr_meanTemp=seq(-2, 2, 1)))
# 
# # diagnosing degenerate matrix, not helpful here
# X1 <- model.matrix(~ddsite_ukbms + ddsite_ukbms_square + siteanom_currsum_meanTemp + 
#     siteanom_spring_meanTemp + siteanom_winter_meanTemp + siteanom_prevsum_meanTemp + 
#     siteanom_prevspr_meanTemp + PC2 + PC3 + siteanom_winter_meanTemp:PC2 + 
#     siteanom_prevspr_meanTemp:PC3, data = datsp)
# (r <- rankMatrix(X1))
# r < ncol(X1)
# (s <- svd(X1))
# mcols <- s$v[, (s$d < .Machine$double.eps)]
# setNames(mcols, colnames(X1))



# marginal effects 











```




```{r season heatmap}



p <- ggplot(avg.mod.coefs, aes(x = Parameters, y = Species)) + 
  geom_tile(aes(fill = Estimate),colour = "black") + 
  scale_fill_gradient2(breaks = c(-.6,-.4, -.2, 0, .2, .4, .6), limits=c(-.6, .6), low = "blue", mid = "white", high = "orange", midpoint = 0) + 
  theme(legend.title = element_blank(), 
        legend.text = element_text(size = 18),
        panel.background = element_rect(fill = "white"), 
        axis.text.y = element_text(size = 18), 
        axis.text.x = element_text(angle=45, vjust=1, hjust = 1, size=18)) + 
  xlab("") + 
  ylab("")
p





```




```{r UHI?}
# Landuse vs siteanomalies
# possible that Daymet (zmean) captures much of the UHI effect 
# one reason why PCs for landuse do not affect butterfly growth rates 

sitetemp <- datmodcut %>%
  group_by(SiteID) %>%
  mutate(index = 1:length(growth_ukbms_add1)) %>%
  filter(index == 1)
sitetemp$lat <- scale(sitetemp$lat)
sitetemp$lon <- scale(sitetemp$lon)



mod <- gls(zmean ~ lat*lon + PC1*PC2, 
               data = sitetemp, 
               correlation = corExp(form = ~ lat + lon))
nullmod <- gls(zmean ~ 1, 
               data = sitetemp, 
               correlation = corExp(form = ~ lat + lon))
r.squaredLR(mod, null = nullmod)

```


```{r randomforest}



datmod$YearFact <- as.factor(datmod$Year)
sitemeans <- readRDS("data/sitemeans.rds")

datmod2 <- merge(datmod, sitemeans[, c("zmean", "SiteID"), with = FALSE], by = "SiteID")

site_geo <- fread("data/OHsites_reconciled.csv", header = TRUE)
site_geo[, SiteID := formatC(as.numeric(Name), width = 3, format = "d", flag = "0")]

# jitter coordinates slightly
site_geo$lat <- site_geo$lat + rnorm(length(site_geo$lat), mean = 0, sd = 0.0001)
site_geo$lon <- site_geo$lon + rnorm(length(site_geo$lon), mean = 0, sd = 0.0001)

datmod2 <- merge(datmod2, site_geo[, c("SiteID", "lat", "lon"), with = FALSE], by = "SiteID")

datmodcut <- datmod2 %>%
  group_by(sp) %>%
  dplyr::mutate(numobs = length(growth_ukbms_add1)) %>%
  dplyr::mutate(ddsite_ukbms_square = I(ddsite_ukbms^2)) %>%
  filter(numobs > 100)

datmodcut <- as.data.frame(datmodcut)

datmodcut <- datmodcut[, c("lat", "lon", "PC1", "PC2", "SiteID", "Year", "YearFact", "sp",
                           "growth_ukbms_add1",
                           "ddsite_ukbms", "ddsite_ukbms_square",
                           "siteanom_currsum_meanTemp",
                           "siteanom_spring_meanTemp",
                           "siteanom_winter_meanTemp",
                           "siteanom_fall_meanTemp",
                           "siteanom_prevsum_meanTemp",
                           "siteanom_prevspr_meanTemp",
                           "zmean")]

spec2model <- unique(datmodcut$sp)


library(randomForest)

rflist <- list()
for (i in 1:length(spec2model)){
  spec <- spec2model[i]
  print(spec)
  rfdat <- datmodcut[which(datmodcut$sp == spec2model[i]), ]
  rfdat$SiteID <- NULL
  rfdat$YearFact <- NULL
  rfdat$sp <- NULL
  rfdat$Year <- NULL
  y <- rfdat$growth_ukbms_add1
  x <- rfdat[, -5]
  mod <- randomForest(x = x, y = y, importance = TRUE, ntree = 1001, mtry = 2)
  rflist[[i]] <- mod
  rflist[[i]]$species <- spec
}

# saveRDS(rflist, "randomForestMods.rds")
# 
# result <- replicate(5, rfcv(x, y), simplify=FALSE)
# error.cv <- sapply(result, "[[", "error.cv")
# matplot(result[[1]]$n.var, cbind(rowMeans(error.cv), error.cv), type="l",
#         lwd=c(2, rep(1, ncol(error.cv))), col=1, lty=1, log="x",
#         xlab="Number of variables", ylab="CV Error")



# library won't install
# 
# library(forestFloor)
# #compute forestFloor object, often only 5-10% time of growing forest
# ff = forestFloor(
#   rf.fit = rfo,       # mandatory
#   X = X,              # mandatory
#   calc_np = FALSE,    # TRUE or FALSE both works, makes no difference
#   binary_reg = FALSE  # takes no effect here when rfo$type="regression"
# )
# 
# 
# #plot partial functions of most important variables first
# plot(ff,                       # forestFloor object
#      plot_seq = 1:6,           # optional sequence of features to plot
#      orderByImportance=TRUE    # if TRUE index sequence by importance, else by X column  
# )

# 
# modlist[["d.c.l.int"]] <- as.formula(growth_ukbms_add1 ~ ddsite_ukbms +
#                                  ddsite_ukbms_square + 
#                                  zmean * (siteanom_currsum_meanTemp + 
#                                             siteanom_spring_meanTemp + 
#                                             siteanom_winter_meanTemp + 
#                                             siteanom_fall_meanTemp +  
#                                             siteanom_prevsum_meanTemp +
#                                             siteanom_prevspr_meanTemp) +
#                                    PC1 * (zmean + siteanom_currsum_meanTemp + 
#                                             siteanom_spring_meanTemp + 
#                                             siteanom_winter_meanTemp + 
#                                             siteanom_fall_meanTemp +  
#                                             siteanom_prevsum_meanTemp +
#                                             siteanom_prevspr_meanTemp) + 
#                                    PC2 * (zmean + siteanom_currsum_meanTemp + 
#                                             siteanom_spring_meanTemp + 
#                                             siteanom_winter_meanTemp + 
#                                             siteanom_fall_meanTemp +  
#                                             siteanom_prevsum_meanTemp +
#                                             siteanom_prevspr_meanTemp) + 
#                                    PC1:PC2)





```



```{r rsa}
# playing around with RSA


  datsp <- datmodcut %>% filter(sp == "Little Wood Satyr") 

  datsp <- as.data.frame(datsp)
  datspmod <- datsp[, c("lat", "lon", "PC1", "PC2", "SiteID", "Year", "YearFact", "sp",
                        "growth_ukbms_add1",
                        "ddsite_ukbms",
                        "siteanom_currsum_meanTemp",
                        "siteanom_spring_meanTemp",
                        "siteanom_winter_meanTemp",
                        "siteanom_fall_meanTemp",
                        "siteanom_prevsum_meanTemp",
                        "siteanom_prevspr_meanTemp",
                        "zmean")]
  datspmod$ddsite_ukbms_square <- I(datspmod$ddsite_ukbms^2)
  
modgls <- gls(growth_ukbms_add1 ~ ddsite_ukbms +
                 ddsite_ukbms_square + 
                 (siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp +
                    siteanom_prevspr_meanTemp)*zmean, 
               data = datspmod, correlation = corExp(form = ~ lat + lon | YearFact),
              method = "ML")

library(nlme)
m2 <- glm(growth_ukbms_add1 ~ ddsite_ukbms +
                 ddsite_ukbms_square + 
                 (siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp +
                    siteanom_prevspr_meanTemp)*zmean, 
               data = datspmod, family = gaussian)


m0 <- gls(growth_ukbms_add1 ~ (siteanom_currsum_meanTemp + 
                    siteanom_spring_meanTemp + 
                    siteanom_winter_meanTemp + 
                    siteanom_fall_meanTemp +  
                    siteanom_prevsum_meanTemp +
                    siteanom_prevspr_meanTemp)*zmean, 
               data = datspmod, method = "ML")
m1 <- gls(growth_ukbms_add1 ~ ddsite_ukbms +
                 ddsite_ukbms_square, 
               data = datspmod, correlation = corExp(form = ~ lat + lon | YearFact),method = "ML")

vario1 <- Variogram(modgls, form = ~lon + lat|YearFact, resType = "pearson")
vario2 <- Variogram(m2, form = ~lon + lat|YearFact, resType = "pearson")

plot(vario1, smooth = TRUE, ylim = c(0, 1.2))

plot(vario2, smooth = TRUE, ylim = c(0, 1.2))

temp <- gls(growth_ukbms_add1 ~ 1,
            data = datspmod, correlation = corExp(form = ~ lat + lon | YearFact),method = "ML")
v <- Variogram(temp, form =  ~lon + lat|YearFact, resType = "pearson")
plot(v)

dists <- dist(site_geo[, c("lat", "lon"), with = FALSE], diag = TRUE, upper = TRUE)
d <- as.matrix(dists)
d[which(d == 0)] <- NA
min.d <- apply(d, 1, min, na.rm = TRUE)
max.d <- apply(d, 1, max, na.rm = TRUE)

num.obs <- apply(d, 1, function(x) length(which(x < 25)))

dists_km <- round(GeoDistanceInMetresMatrix(as.data.frame(site_geo[, c("lat", "lon"), with = FALSE])) / 1000)

```







Quick code to scale sites by mean temperature, accounting for random pts around OH.
Doesn't look like it should actually matter. Forget about it for now.

```{r site mean temperature}
setwd("C:/Users/Tyson/Desktop/Box Sync/Ohio/daymet")


site_geo <- fread("C:/Users/Tyson/Desktop/Box Sync/Ohio/GIS/OHsites_reconciled.csv", header = TRUE)
site_geo[, SiteID := formatC(as.numeric(Name), width = 3, format = "d", flag = "0")]
setwd("C:/Users/Tyson/Desktop/Box Sync/Ohio/daymet")
source("revised.climdex.functions.R")




DaymetSiteMean <- function(datafile){
  source("revised.climdex.functions.R")

  all_content = readLines(datafile)
  skip_lead = all_content[-c(1:6)]
  data = read.csv(textConnection(skip_lead), header = TRUE, stringsAsFactors = FALSE)
  
  data$date <- strptime(paste(data$year, data$yday, sep = " "), format = "%Y %j")
  data$month <- month(data$date)
  
  site <- unlist(strsplit(datafile, "[/]"))[2]
  site <- unlist(strsplit(site, "[.]"))[1]
  site <- unlist(strsplit(site, "e"))[2]
  data$site <- site
  data <- data[which(data$year >= 1995), ]

  names(data)[3] <- "tmax"
  names(data)[4] <- "tmin"
  names(data)[6] <- "prcp"
  names(data)[8] <- "snow"
  
  data <- data[, c("year", "yday", "tmax", "tmin", "prcp", "snow", "date", "month", "site")]
  
  clim.input <- climdexInput.Tyson(tmax = data$tmax, tmin = data$tmin, prec = data$prcp,
                                   tmax.dates = as.PCICt(data$date, "365"), 
                                   tmin.dates = as.PCICt(data$date, "365"), 
                                   prec.dates = as.PCICt(data$date, "365"), 
                                   base.range = c(1980, 2014), n = 5 , northern.hemisphere = TRUE, 
                                   temp.qtiles = c(.1, .9))
# new temp mean function
meanTempAll <- function(ci){
  ts <- ci@data$tavg
  return(mean(ci@data$tavg, na.rm = TRUE))
}
  
  #season functions that work
  meanTemp <- meanTempAll(clim.input)
  
  out <- data.frame(site = site, meanTemp)
  return(out)
}

#run lapply on all daymet files with function, then rbindlist
sitefilenames <- as.list(paste("sites", list.files("sites"), sep = "/"))
randomfilenames <- as.list(paste("randomPts", list.files("randomPts"), sep = "/"))

# too slow
# datSites <- lapply(sitefilenames, DaymetSiteMean)
# datRandom <- lapply(randomfilenames, DaymetSiteMean)


library(parallel)
# Calculate the number of cores
no_cores <- detectCores()-1
 
# Initiate cluster
cl <- makeCluster(no_cores)
clusterEvalQ(cl, {library(lubridate); library(climdex.pcic); library(reshape); library(dplyr)})
datSites <- parLapply(cl, sitefilenames, DaymetSiteMean)
datRandom <- parLapply(cl, randomfilenames, DaymetSiteMean)
stopCluster(cl)

library(data.table)
meanSites <- rbindlist(datSites)
meanRand <- rbindlist(datRandom)

meanRand$site <- paste("R", as.character(meanRand$site), sep = "")

# scaling alone
meanSites$zmean <- scale(meanSites$meanTemp)
meanRand$zmean <- scale(meanRand$meanTemp)

# scaling together
means <- rbind(meanSites, meanRand)
means$zmeanall <- scale(means$meanTemp)

sitemeans <- means[-grep("R", site)]
plot(sitemeans$zmean, sitemeans$zmeanall)


sitemeans[, SiteID := formatC(as.numeric(as.character(site)), width = 3, format = "d", flag = "0")]
saveRDS(sitemeans, "data/sitemeans.rds")

```




```{r plotting model}

library(sjPlot)
# sjp.setTheme(theme = theme_minimal())

weather <- mods[[6]]
sjt.lmer(weather, file = "weather.html")
r.squaredGLMM(weather)


sjp.lmer(weather,facet.grid = FALSE,
         sort.coef = "sort.all")
# sjp.lmer(weather, "coef")

sjp.lmer(weather, type = "poly", poly.term = "Zwinter")
sjp.int(weather, type = "eff")  
  
  
  
  
```
  
  
  
  
Tangent
Species traits and the phylogeny
Chapter 3 work on common vs less common species in Ohio

```{r phylo traits}

# from dataviz
trends <- readRDS("spec.trend.rds")


mods <-  trends %>% group_by(CommonName) %>%
  do(fits = lm(CollInd ~ Year, data = .))
modsCoef = tidy(mods, fits)
modsYear <- modsCoef %>% filter(term == "Year")

growth <- modsYear %>% data.frame()
growth$col <- NA
growth$Trend <- NA
growth$col[which(growth$estimate >= .05)] <- "#2c7bb6"
growth$col[which(growth$estimate <= -.05)] <- "#d7191c"
growth$col[which(abs(growth$estimate) < .05 & growth$estimate < 0)] <- "#fdae61"
growth$col[which(abs(growth$estimate) < .05 & growth$estimate > 0)] <- "#abd9e9"
growth$Trend[which(growth$estimate >= .05)] <- "Increase"
growth$Trend[which(growth$estimate <= -.05)] <- "Decrease"
growth$Trend[which(abs(growth$estimate) < .05 & growth$estimate < 0)] <- "Slight decrease"
growth$Trend[which(abs(growth$estimate) < .05 & growth$estimate > 0)] <- "Slight increase"

growthcols <- c("#E31A1C", "#2171B5","#FD8D3C", "#6BAED6")


setwd("../Chap1-Bfly-Landuse-Climate/")
library(ape)
best.tree <- read.tree(file = "data/bestTree.txt")
constr.tree <- read.tree(file = "data/constrained.txt")
tr <- best.tree

edge.col <- c(rep("blue", nrow(tr$edge)))
tips <- which(tr$edge[,2] <= length(tr$tip.label))
edge.col[tips] <- "red"

plot.phylo(tr, type = "phylogram", use.edge.length = TRUE, edge.color = edge.col, cex = .5)


sptraits <- datmod %>%
  group_by(sp) %>%
  dplyr::summarise(numobs = length(growth_ukbms_add1), 
                meangrowth = mean(growth_ukbms_add1),
                medcount = median(RawSum))
names(sptraits)[1] <- "CommonName"

OHtraits <- read.csv("C:/Users/Tyson/Desktop/Box Sync/Dissertation/OHtraits_R.csv") 
OHtraits$CommonName <- as.character(OHtraits$CommonName)
OHtraits$CommonName[2] <- "Azures"
OHtraits <- OHtraits[1:120, c("CommonName", "MaxBroodNumb", "ResStatus", "WinterStage", "GenvsSpec")]

SpeciesList <- readRDS("SpeciesList.rds")


traits <- merge(SpeciesList, OHtraits, by = "CommonName", all.x = TRUE)
traits <- merge(traits, sptraits, by = "CommonName", all.x = TRUE)
traits <- merge(SpeciesList, growth, by = "CommonName", all.x = TRUE)

traits$CommonName <- gsub(" ", "", traits$CommonName, fixed = TRUE)

phy.tips <- data.frame(tip = 1:length(tr$tip.label), CommonName = tr$tip.label)
spec <- merge(traits, phy.tips, by= "CommonName", all = TRUE)

spec$col[which(is.na(spec$col))] <- "#252525"



# remove species from tree that don't show up in OH
spec <- spec[which(spec$Present >= 10), ]
spec <- spec[-which(is.na(spec$tip)), ]
rm.tips <- phy.tips$tip[-which(phy.tips$tip %in% spec$tip)]
tr.edit <- drop.tip(tr, rm.tips)


edge.col <- c(rep("blue", nrow(tr.edit$edge)))
tips <- which(tr.edit$edge[,2] <= length(tr.edit$tip.label))
edge.col[tips] <- "red"

plot.phylo(tr.edit, type = "phylogram", use.edge.length = FALSE, edge.color = edge.col, cex = .5)


library(picante)
spec$Trend <- as.factor(spec$Trend)
color.plot.phylo(tr.edit, spec, trait = "Trend", taxa.names = "CommonName",
                 col.names = growthcols, use.edge.length = FALSE)


library(RColorBrewer)
growthCol <- brewer.pal(3, "RdYlGn")
WintStgCol <- brewer.pal(4,"Set2")
BroodCol <- brewer.pal(5, "Set2")

# reorder spec data.frame, tip coloumn no longer useful after edited tree
spec$CommonName <- factor(spec$CommonName, levels = tr.edit$tip.label)
spec <- droplevels.data.frame(spec)
spec$MaxBroodNumb <- factor(spec$MaxBroodNumb, levels = c(1:5))
spec_ord <- with(spec, spec[order(CommonName),])
WinTips <- spec_ord$WinterStage
WinCol <- as.character(mapvalues(WinTips, from = levels(WinTips), to = WintStgCol))
WinCol[is.na(WinCol)] <- "#B3B3B3"

edge.col <- c(rep("blue", nrow(tr.edit$edge)))
tips <- which(tr.edit$edge[,2] <= length(tr.edit$tip.label))
edge.col[tips] <- WinCol

plot.phylo(tr.edit, type = "phylogram", use.edge.length = FALSE, edge.color = edge.col, cex = .5)


library(picante)
color.plot.phylo(tr.edit, spec, trait = "WinterStage", taxa.names = "CommonName",
                 col.names = WintStgCol, use.edge.length = FALSE)

color.plot.phylo(tr.edit, spec, trait = "MaxBroodNumb", taxa.names = "CommonName",
                 col.names = BroodCol, use.edge.length = FALSE)

color.plot.phylo(tr.edit, spec, trait = "GenvsSpec", taxa.names = "CommonName",
                 col.names = WintStgCol, use.edge.length = FALSE)


color.plot.phylo(tr.edit, spec, trait = "ResStatus", taxa.names = "CommonName",
                 col.names = WintStgCol[1:3], use.edge.length = FALSE)

spec$logPres <- log(spec$Present)

color.plot.phylo(tr.edit, spec, trait = "logPres", taxa.names = "CommonName",
                 num.breaks = 3, col.names = WintStgCol[1:3], use.edge.length = FALSE,
                 main = "Log(Number of sightings)")


color.plot.phylo(tr.edit, spec, trait = "meangrowth", taxa.names = "CommonName",
                 num.breaks = 2, col.names = c("red", "forest green"), use.edge.length = FALSE,
                 main = "Ohio butterfly mean annual population growth rate and missing estimates")
legend("bottomleft", legend=c("Declining", "Growing", "Data deficient"),
   fill=c("red", "forest green", "black"), cex = 1.5)

plot(spec$WinterStage, spec$meangrowth)
plot(spec$GenvsSpec, spec$meangrowth)
plot(spec$MaxBroodNumb, spec$meangrowth)
plot(spec$numobs, spec$meangrowth)

plot(spec$GenvsSpec[which(spec$numobs > 140)])
plot(spec$GenvsSpec[-which(spec$numobs > 140)])

plot(spec$WinterStage[which(spec$numobs > 140)])
plot(spec$WinterStage[-which(spec$numobs > 140)])

plot(spec$MaxBroodNumb[which(spec$numobs > 140)])
plot(spec$MaxBroodNumb[-which(spec$numobs > 140)])


```









